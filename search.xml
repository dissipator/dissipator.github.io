<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux下安装virtualbox虚拟机命令操作]]></title>
    <url>%2F2018%2F05%2F23%2Flinux%E4%B8%8B%E5%AE%89%E8%A3%85virtualbox%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[linux下安装virtualbox虚拟机命令操作inux下安装virtualbox虚拟机命令操作 无意间看到一篇虚拟机性能介绍的文章，说到开源的virtualbox性很不错，于是最近到官方网站www.virtualbox.org下了当前最新版本VirtualBox-3.1-3.1.2_56127学习研究了一下，开始在windows 7下虚拟安装xp及centeros5系统操作了一下，启动速度比vmware要快得多，操作习惯上也很相似，又在linux下操作了一番，界面操作启动和在windows上差不多，虚拟机上xp启动的速度一般在16-17秒左右，在一台 Intel(R) Xeon(R) CPU 1.86GHz （双CPU,4核每CPU），8G内存，Red Hat 3.4.6-8 linux操作系统下（系统自身比较干净，还没安装过其他应用），同时创建了3台虚拟1CPU,1G内存，xp，X界面下操作几乎同时启动，实体机瞬间当前LOAD高达14，感觉很卡，同时不知道何故，3台XP完全启动后其中总一台5分钟内会挂掉。后来改用命令模式操作，3台起来一点问题都没有，xp上跑一些自动测试脚本，观察了一天，还算稳定，有空计划继续往上加上几台看看。 桌面界面上操作相对比较简单，命令操作有点复杂，但是性能比较高，下面介绍一下命令模式下安装操作过程。 1.rpm包安装​ rpm -ivh VirtualBox-3.1-3.1.2_56127_rhel4-1.i386.rpm 因为我的系统版本比较老是RHEL3,不过内核升级到了2.6.9，本想找源码包编译安装，直接拿这个在上面rpm包安装试了好像也没报错。 2.添加vboxusers 用户组​ usermod -a -G vboxusers root 上面virtualbox rpm包安装好后会自动生成vboxusers组，系统上要用虚拟机的用户都可以把这个组添加进去。 3.创建虚拟机​ VBoxManage createvm –name “winxp” –register VBoxManage 是virtualbox的虚拟机管理命令，命令模式下操作几乎都跟他有关。这里创建了一个winxp的虚拟机。 创建完后可以用 VBoxManage list vms 命令查看一下当前可用的虚拟机，也可以用VBoxManage showvminfo winxp 命令查看一下当前虚拟机winxp的状态及一些默认配置。 #4.修改虚拟机设置 4.修改虚拟机设置​ 首先先创建一个磁盘： VBoxManage createmedium [disk|dvd|floppy] –filename [–size |–sizebyte ] [–diffparent | [–format VDI|VMDK|VHD] (default: VDI) [–variant Standard,Fixed,Split2G,Stream,ESX] ​ VBoxManage createvdi –filename /home/virtualbox/winxp.vdi –size 5000 –remember 修改虚拟机winxp设置，操作系统，内存，显存，启动顺序，磁盘位置，sata磁盘控制器，电源管理接口，CPU设置，网卡接口，远程管理等 Warning: ‘–vrdp’ is deprecated. Use ‘–vrde’.Warning: ‘–vrdpport’ is deprecated. Use ‘–vrdeport’.Warning: ‘–vrdpmulticon’ is deprecated. Use ‘–vrdemulticon’. VBoxManage modifyvm “winxp” –ostype “WindowsXP” –memory “512” –vram “16” –boot2 disk –boot1 dvd –hda “/home/virtualbox/winxp.vdi” –sata on –acpi on –pae on –hwvirtex on –nic1 hostif –cableconnected1 on –nictype1 “Am79C973” –bridgeadapter1 eth0 –intnet1 brigh1 –macaddress1 auto –vrdp on –vrdpport 4000 –vrdpmulticon on 上面参数具体说明可以用 VBoxManage modifyvm –help 查看了解执行上面命令，可能会碰到如下错误：ERROR: Could not find a storage controller named ‘IDE Controller’ 在国外网站上查到需要添加一下IDE接口就可以了，执行如下命令：VBoxManage storagectl winxp –name “IDE Controller” –add ide再执行上面命令即可。 5.挂载ISO安装盘​ VBoxManage openmedium dvd /home/virtualbox/winxpsp3.iso 6.系统安装​ 先将挂载的ISO文件，加到虚拟机的DVD光驱里VBoxManage modifyvm “winxp” –dvd /home/virtualbox/winxpsp3.iso可能会报错： ERROR: No storage device attached to device slot 0 on port 1 of controller ‘IDE Controller’ 是IDE 端口没设置好执行如下操作： 将winxp.vdi 磁盘放在设备0的第0个端口 VBoxManage storageattach winxp –storagectl “IDE Controller” –port 0 –device 0 –type hdd –medium /home/virtualbox/winxp.vdi将ISO挂载在设备0的第1个端口 VBoxManage storageattach winxp –storagectl “IDE Controller” –port 1 –device 0 –type dvddrive –medium /home/virtualbox/winxpsp3.iso 7.开始启动​ VBoxManage startvm “winxp” -type vrdp 或者 VBoxHeadless -startvm “winxp” &amp;、 第一种：使用 VRDP 方式通过命令行启动虚拟机： (虚拟机名为：dcsvr08)QHo@qhoferrari1k:~$ VBoxManage startvm dcsvr08 -type vrdp 第二种 ：使用 Headless 启动无前端图形界面方式： QHo@qhoferrari1k:~$ VBoxHeadless -startvm “dcsvr08” 再通windows远程桌面远程连接过去，IP:4000 ，这个端口是之前设置好的，也可以启动的时候加参数，没有加密，直接连远程连接操作。 8.安装客户端增强插件 mkdir /mnt/iso mount -o loop /usr/share/virtualbox/VBoxGuestAdditions.iso /mnt/iso 进入系统，打开光驱安装即可 9.系统复制克隆 virtualbox 不像vmware的磁盘文件，拷贝过来是不能直接使用，因为virtualbox的磁盘文件里都被记录了独立的uuid，所以复制只能用自带的命令克隆磁盘。 vboxmanager clonevdi $(pwd)/winxp.vdi $（pwd）/winxp2.vdi 注意，路径要写全，因为默认路径会指向/root/.virtualbox/ 然后再添加注册个虚拟机： VBoxManage createvm –name “winxp1” –register 查看一下默认设置： VBoxManage showvminfo winxp2 修改虚拟机配置： VBoxManage modifyvm “winxp2” –ostype “WindowsXP” –memory “512” –vram “16” –boot1 disk –boot2 dvd –hda “/home/virtualbox/winxp2.vdi” –sata on –acpi on –pae on –hwvirtex on –nic1 hostif –cableconnected1 on –nictype1 “Am79C973” –bridgeadapter1 eth0 –intnet1 brigh2 –macaddress1 auto –vrdp on –vrdpport 5000 –vrdpmulticon on 启动系统：VBoxManage startvm “winxp” -type vrdp 10.文件共享（数据空间） virtulbaox 可以通过映射，直接将实体机文件共享到虚拟机中。VBoxManage sharedfolder add winxp –name share –hostpath /home/virtualbox/share –transient界面下操作很简单，数据空间打开实体机文件，虚拟机打开网络映射挂载上来就可以。如果虚拟机是linux，需要加载磁盘格式模块： modprobe vboxvfs mount -t vboxsf share_net_filename（实体机共享名） /home/virtualbox/share（虚拟机中文件路径）这样基本实现了virtualbox在linux命令下安装，virtualbox命令很多，还在继续研究学习中。 3389是VRDP（远程桌面）监听端口 。 启用VRDP后，一旦虚拟机启动完毕，我们就可以通过远程桌面/XManage等GUI远程管理工具来登录客户操作系统 。 要确认虚拟机是否在运行 ，可以使用命令VBoxManage list runningvm 来查看。QHo@qhoferrari1k:~$ VBoxManage list runningvms 从命令行关闭虚拟机通过VBoxManage 命令行工具的VBoxManage controlvm | 子命令可以改变虚拟机的运行状态，其中常用的几个选项是： pause resume reset poweroff savestate acpipowerbutton acpisleepbutton下面示例使用 poweroff 选项关闭虚拟机 dcsvr08 QHo@qhoferrari1k:~$ VBoxManage controlvm dcsvr08 poweroffVirtualBox Command Line Management Interface Version 2.1.4(C) 2005-2009 Sun Microsystems, Inc.All rights reserved. QHo@qhoferrari1k:~$ VBoxManage list runningvmsVirtualBox Command Line Management Interface Version 2.1.4(C) 2005-2009 Sun Microsystems, Inc.All rights reserved. 3ce3fd01-7e17-46b3-8394-be9c1b17ee66QHo@qhoferrari1k:~$在poweroff 后马上list runningvms ，可以看到dscvr08已经被关闭，现在只有一台虚机处于运行状态。 http://fengshihua.cublog.cn 据有资料说：虚拟机上安装的虚拟系统的内存使用量必须要符合VBOX的要求，即不能超过机器物理内存的40％，换言之，要预留足够的内存供真实系统使用，否则会经常异常死机，或无法运行虚拟系统。举例：我机器内存为512M，虚拟XP分配128M内存，显存分配32M即可。如果虚拟XP分配256M内存，则无法正常运行虚拟，总是异常退出。 环境：Ubuntu 15.04 64bit，virtualbox 5.0.16 准备：下载安装好virtualbox,virtualbox-extensions，准备好iso系统文件，如archlinux.iso。 1.建立好vbox的目录。 $ cd$ cd VirtualBox\ VMs/$ mkdir arch$ cd arch 2.新建一个vbox磁盘，–size参数设置大小，单位：M。 $ vboxmanage createmedium disk –filename arch.vdi –size 10000 3.新建vbox虚拟机文件，–ostype设置虚拟机安装的系统格式（windows/ubuntu等），可以使用vboxmanage list ostypes查看vbox支持的系统格式。 $ vboxmanage createvm –name arch –ostype “linux_64” –register 4.新建SATA磁盘控制器并将步骤中新建的磁盘绑定到虚拟机文件。 $ vboxmanage storagectl arch –name “SATA Controller” –add sata –controller IntelAHCI$ vboxmanage storageattach arch –storagectl “SATA Controller” –port 0 –device 0 –type hdd –medium arch.vdi 5.新建IDE控制器，设置它为dvd，并绑定ios文件到该dvd，注意–medium为你的iso路径。 $ vboxmanage storagectl arch –name “IDE Controller” –add ide$ vboxmanage storageattach arch –storagectl “IDE Controller” –port 0 –device 0 –type dvddrive –medium /path/to/arch.iso 5.查看自己的网卡，并设置vbox网卡为桥接。 $ ifconfig 输出： wlp18s0 Link encap:Ethernet HWaddr xx:xx:xx:xx:xx:xxinet addr:192.168.0.101 Bcast:192.168.0.255 Mask:255.255.255.0 我的网卡是wlp18s0，所以将vbox nic1网卡绑定到它。 $ vboxmanage modifyvm arch –nic1 bridged –bridgeadapter1 wlp18s0 6.设置io控制，启动项，内存等。 $ vboxmanage modifyvm arch –ioapic on$ vboxmanage modifyvm arch –boot1 dvd –boot2 disk –boot3 none –boot4 none$ vboxmanage modifyvm arch –memory 1024 –vram 128 7.设置rdpe远程桌面。 $ vboxmanage modifyvm arch –vrdeport 3389 –vrdeaddress 0.0.0.0 8.后台开启vbox。 $ vboxmanage startvm arch –type=headless 9.现在就可以用rdesktop联接后台了 $ rdesktop localhost:3389 rdesktop xxx.xxx.xx.xx:3389 10.安装完成后退出dvd上的iso。 $ vboxmanage storageattach arch –storagectl “IDE Controller” –port 0 –device 0 –type dvddrive –medium none 11.查看正在运行的vbox系统，关机。 $ vboxmanage list runningvms$ vboxmanage controlvm arch poweroff 最后，其余功能可以查看帮助。 $ vboxmanage –help webvbox wget ‘http://sourceforge.net/projects/phpvirtualbox/files/latest/download&#39;]]></content>
  </entry>
  <entry>
    <title><![CDATA[ipcalc]]></title>
    <url>%2F2018%2F05%2F20%2Fipcalc%2F</url>
    <content type="text"><![CDATA[ip地址计算器ipcalc 192.168.3.1/22Address: 192.168.3.1 11000000.10101000.000000 11.00000001Netmask: 255.255.252.0 = 22 11111111.11111111.111111 00.00000000Wildcard: 0.0.3.255 00000000.00000000.000000 11.11111111=&gt;Network: 192.168.0.0/22 11000000.10101000.000000 00.00000000HostMin: 192.168.0.1 11000000.10101000.000000 00.00000001HostMax: 192.168.3.254 11000000.10101000.000000 11.11111110Broadcast: 192.168.3.255 11000000.10101000.000000 11.11111111Hosts/Net: 1022 Class C, Private Internet]]></content>
      <tags>
        <tag>network，linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在IRC里使用weixin和qq]]></title>
    <url>%2F2018%2F05%2F16%2F%E5%9C%A8IRC%E9%87%8C%E4%BD%BF%E7%94%A8weixin%E5%92%8Cqq%2F</url>
    <content type="text"><![CDATA[本文章是介绍怎么在linux的IRC客户端weechat里，进行qq和微信聊天安装perl的Mojo-ActivePerl 下载ZIP压缩包(约43M) 12345$ wget https://github.com/sjdy521/Mojo-ActivePerl/archive/master.zip -O Mojo-ActivePerl.zip#如果下载速度较慢可以使用国内的腾讯云存储地址（文件可能会较旧）$ wget http://share-10066126.cos.myqcloud.com/Mojo-ActivePerl-20170214.zip -O Mojo-ActivePerl.zip 解压到当前目录并进入目录 12$ unzip Mojo-ActivePerl.zip$ cd Mojo-ActivePerl-master 运行安装脚本，指定安装目录(需要有权限创建和写入) 1$ sh install.sh --prefix /usr/local/Mojo-ActivePerl #这里以/usr/local/Mojo-ActivePerl目录为例 把如下perl和cpanm所在目录(/usr/local/Mojo-ActivePerl/bin/)添加到PATH环境变量（或不设置环境变量，直接使用绝对路径） 12$ /usr/local/Mojo-ActivePerl/bin/perl$ /usr/local/Mojo-ActivePerl/bin/cpanm 安装weechat1sudo apt install weechat 编写脚本Mojo::Weixin;12345#!/usr/bin/env perlmy $client = Mojo::Weixin-&gt;new();$client-&gt;load(&quot;ShowMsg&quot;);$client-&gt;load(&quot;IRCShell&quot;); #加载IRCShell插件$client-&gt;run(); 启动服务perl 脚本 用weecgat，链接到服务12weechat/server add webqq xxxxxxx 开始聊天/join /query /nick]]></content>
  </entry>
  <entry>
    <title><![CDATA[OpsManager]]></title>
    <url>%2F2018%2F05%2F10%2FOpsManager%2F</url>
    <content type="text"><![CDATA[Docker构建OpsManage要求具备一定docker基础： 构建步骤： 1234$ mkdir -p /data/opsmanage$ cd /data/opsmanage$ git clone https://github.com/welliamcao/OpsManage.git$ cd OpsManage 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061$ vim start.sh#!/bin/bashecho_supervisord_conf &gt; /etc/supervisord.confexport PYTHONOPTIMIZE=1cat &gt; /etc/supervisord.conf &lt;&lt; EOF[unix_http_server]file=/tmp/supervisor.sock [supervisord]logfile=/tmp/supervisord.log logfile_maxbytes=50MB logfile_backups=10 loglevel=info pidfile=/tmp/supervisord.pid nodaemon=false minfds=1024 minprocs=200 [rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket[program:celery-worker-default]command=/usr/bin/python manage.py celery worker --loglevel=info -E -Q defaultdirectory=/mnt/OpsManagestdout_logfile=/var/log/celery-worker-default.logautostart=trueautorestart=trueredirect_stderr=truestopsignal=QUITnumprocs=1[program:celery-worker-ansible]command=/usr/bin/python manage.py celery worker --loglevel=info -E -Q ansible directory=/mnt/OpsManagestdout_logfile=/var/log/celery-worker-ansible.logautostart=trueautorestart=trueredirect_stderr=truestopsignal=QUITnumprocs=1[program:celery-beat]command=/usr/bin/python manage.py celery beatdirectory=/mnt/OpsManagestdout_logfile=/var/log/celery-beat.logautostart=trueautorestart=trueredirect_stderr=truestopsignal=QUITnumprocs=1[program:celery-cam]command=/usr/bin/python manage.py celerycamdirectory=/mnt/OpsManagestdout_logfile=/var/log/celery-celerycam.logautostart=trueautorestart=trueredirect_stderr=truestopsignal=QUITnumprocs=1EOF/usr/bin/supervisord -c /etc/supervisord.confsleep 3cd /mnt/OpsManage/python /mnt/OpsManage/manage.py runserver 0.0.0.0:8000 12345678910111213$ vim superuser.json[ &#123; &quot;model&quot;: &quot;auth.user&quot;, &quot;pk&quot;: 1, &quot;fields&quot;: &#123; &quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;pbkdf2_sha256$36000$eijqZp5ctxnE$xxCcAo/Rsuc+HddjGLQ6dUo/kDnuvayazUZ4V3xz52w=&quot;, &quot;is_superuser&quot;: true, &quot;is_staff&quot;: true, &quot;is_active&quot;: true &#125; &#125;] 1234567891011$ cd ../$ vim DockerfileFROM centos:latestRUN yum install -y wget git zlib zlib-devel readline-devel sqlite-devel bzip2-devel openssl-devel gdbm-devel libdbi-devel ncurses-libs kernel-devel libxslt-devel libffi-devel python-devel mysql-devel zlib-devel sshpass libtool makeRUN cd /usr/local/src &amp;&amp; wget --no-check-certificate https://github.com/pypa/pip/archive/1.5.5.tar.gz -O pip-1.5.5.tar.gz &amp;&amp; wget --no-check-certificate https://pypi.python.org/packages/f7/94/eee867605a99ac113c4108534ad7c292ed48bf1d06dfe7b63daa51e49987/setuptools-28.0.0.tar.gz#md5=9b23df90e1510c7353a5cf07873dcd22RUN cd /usr/local/src &amp;&amp; tar -xzvf setuptools-28.0.0.tar.gz &amp;&amp; tar -xzvf pip-1.5.5.tar.gz &amp;&amp; cd setuptools-28.0.0 &amp;&amp; python setup.py install &amp;&amp; cd ../pip-1.5.5 &amp;&amp; python setup.py install &amp;&amp; pip install -U pip &amp;&amp; easy_install paramiko==2.4.1RUN mkdir -p /etc/ansible/ &amp;&amp; echo -ne &quot;[defaults]\nlibrary = /usr/share/ansible/my_modules/\nhost_key_checking = False\n&quot; &gt; /etc/ansible/ansible.cfg &amp;&amp; echo &quot;welliam&quot; | passwd --stdin rootADD OpsManage /mnt/OpsManage/RUN pip install -r /mnt/OpsManage/requirements.txt &amp;&amp; cd /mnt/OpsManage/ &amp;&amp; python manage.py makemigrations OpsManage &amp;&amp; python manage.py makemigrations wiki &amp;&amp; python manage.py migrate &amp;&amp; python manage.py loaddata superuser.jsonCMD bash /mnt/OpsManage/start.shEXPOSE 8000 :wq 保存退出 2、修改OpsManage setting.py配置文件里面的MySQL与Redis设置 1$ vim /data/opsmanage/OpsManage/OpsManage/settings.py 3、Docker build构建基础镜像： 1$ docker build -t opsmanage:base . 注：第一次构建时间会很长，要注意等待或者是否出错 4、Docker run运行刚刚构建的镜像 1$ docker run -d --name=opsmanage -v /data/opsmanage/OpsManage:/mnt/OpsManage -p 8000:8000 -p 2222:22 opsmanage:base 5、浏览器访问http://ip:8000 默认账户密码是admin/admin]]></content>
  </entry>
  <entry>
    <title><![CDATA[chromedriver与chrome版本映射表]]></title>
    <url>%2F2018%2F05%2F01%2Fchromedriver%E4%B8%8Echrome%E7%89%88%E6%9C%AC%E6%98%A0%E5%B0%84%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[看到网上基本没有最新的chromedriver与chrome的对应关系表，便兴起整理了一份如下，希望对大家有用： http://chromedriver.storage.googleapis.com/2.9/notes.txt 123456echo "" &gt;ch.list for i in `curl -s http://npm.taobao.org/mirrors/chromedriver| grep -e "chromedriver/[0-9].[0-9]*"| awk -F'/' '&#123;print $4&#125;'`do curl -s http://npm.taobao.org/mirrors/chromedriver/$i/notes.txt|grep -v "fails" |grep -e"v[0-9]*[.\-][0-9]*"&gt;&gt;ch.list done 结果如下： 12cat ch.list| awk -F'V| ' '&#123;if($1=="Supports")&#123;print "Supports Chrome " $3$4&#125;else&#123;print $2$3&#125;&#125;'#用ｐｒｉｎｔｆ会混乱 ChromeDriver v2.9(2014-01-31)----------&gt;Chrome:v31-34 ChromeDriver v2.8(2013-12-16)----------&gt;Chrome:v30-33 ChromeDriver v2.7(2013-11-22)----------&gt;Chrome:v30-33 ChromeDriver v2.6(2013-11-04)----------&gt;Chrome:v29-32 ChromeDriver v2.5(2013-11-01)----------&gt;Chrome:v29-32 ChromeDriver v2.4(2013-09-30)----------&gt;Chrome:v29-32 ChromeDriver v2.37(2018-03-16)----------&gt;Chrome:v64-66 ChromeDriver v2.36(2018-03-02)----------&gt;Chrome:v63-65 ChromeDriver v2.35(2018-01-10)----------&gt;Chrome:v62-64 ChromeDriver v2.34(2017-12-10)----------&gt;Chrome:v61-63 ChromeDriver v2.33(2017-10-03)----------&gt;Chrome:v60-62 ChromeDriver v2.32(2017-08-30)----------&gt;Chrome:v59-61 ChromeDriver v2.3(2013-09-02)---------- ChromeDriver v2.31(2017-07-21)----------&gt;Chrome:v58-60 ChromeDriver v2.30(2017-06-07)----------&gt;Chrome:v58-60 ChromeDriver v2.29(2017-04-04)----------&gt;Chrome:v56-58 ChromeDriver v2.28(2017-03-09)----------&gt;Chrome:v55-57 ChromeDriver v2.27(2016-12-23)----------&gt;Chrome:v54-56 ChromeDriver v2.26(2016-12-09)----------&gt;Chrome:v53-55 ChromeDriver v2.25(2016-10-25)----------&gt;Chrome:v53-55 ChromeDriver v2.24(2016-09-09)----------&gt;Chrome:v52-54 ChromeDriver v2.23(2016-08-04)----------&gt;Chrome:v51-53 ChromeDriver v2.22(2016-06-06)----------&gt;Chrome:v49-52 ChromeDriver v2.2(2013-08-06)---------- ChromeDriver v2.21(2016-01-28)----------&gt;Chrome:v46-50 ChromeDriver v2.20(2015-10-08)----------&gt;Chrome:v43-48 ChromeDriver v2.19(2015-08-28)----------&gt;Chrome:v43-47 ChromeDriver v2.18(2015-08-19)----------&gt;Chrome:v43-46 ChromeDriver v2.15(2015-03-26)----------&gt;Chrome:v40-43 ChromeDriver v2.14(2015-01-28)----------&gt;Chrome:v39-42 ChromeDriver v2.13(2014-12-10)----------&gt;Chrome:v38-41 ChromeDriver v2.12(2014-10-27)----------&gt;Chrome:v36-40 ChromeDriver v2.11(2014-10-07)----------&gt;Chrome:v36-40 ChromeDriver v2.10(2014-05-01)----------&gt;Chrome:v33-36 http://chromedriver.storage.googleapis.com/index.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[实现Zabbix通过邮件发送图形报表]]></title>
    <url>%2F2018%2F04%2F26%2F%E5%AE%9E%E7%8E%B0Zabbix%E9%80%9A%E8%BF%87%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%E5%9B%BE%E5%BD%A2%E6%8A%A5%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[实现Zabbix通过邮件发送图形报表在使用Zabbix的过程中，我们通常会建立一些需要图形报表来汇总需要监控的Graph。而下面的两个脚本，则是通过从Zabbix数据库中获取所有的图形数据，提供Zabbix的WEB接口将所有图形保存到本地，然后通过脚本以Email形式发送过来，作为每天的自动报表。 在本地创建/data/cscript 和 /data/graph 目录 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#!/usr/bin/perluse File::Path;use DBI;use Net::FTP;##定义graph路径，判断graph目录是否存在，不存在则自动新建my $path = &apos;/data/graph&apos;;if(-e $path) &#123; rmtree($path); &#125;mkdir($path);#my $stime = `date +%Y%m%d`; chop($stime); $stime .= &apos;1000&apos;;if( length($stime) != 12 ) &#123; print &quot;Error get date&quot;; exit; &#125;##指定截图图形的时间轴周期my $period = 21600; # 6 hours##定义Web的登陆名及密码my $login = &apos;admin&apos;; # Zabbix Web Usermy $pass = &apos;password&apos;; # Zabbix Web User Password, must be URL Encoded##定义FTP账号密码my $ftp_site = &apos;ftp.corp.intra&apos;;my $ftp_user_name = &apos;zabbix&apos;;my $ftp_password = &apos;zabbix&apos;;##定义cookie的路径my $cook = &quot;/tmp/cookie&quot;;##指定链接数据库my $dsn = &apos;DBI:mysql:zabbix:localhost&apos;; # Connect MySQL DB &quot;zabbix&quot; on localhostmy $db_user_name = &apos;zabbix&apos;; # MySQL DB usermy $db_password = &apos;dbpassword&apos;; # MySQL DB user passwordmy $dbh = DBI-&gt;connect($dsn, $db_user_name, $db_password);##查询存在哪些screenmy $sth = $dbh-&gt;prepare(qq&#123;select a.name,a.hsize,a.vsize, b.resourceid, b.width, b.height,b.x,b.y from screens a,screens_items as b where a.screenid=b.screenid and a.templateid&lt;=&gt;NULL order by a.name&#125;);$sth-&gt;execute();my %screens;## Get all graphs by using curlwhile (my ($name,$hsize,$vsize, $id,$width,$height,$x,$y) = $sth-&gt;fetchrow_array())&#123;##长度大于2位的是graph，小于2位的表示是MAPif(length($id) &gt; 2)&#123;#print &quot;$id =&gt; $ids\n&quot;;##定义导出的文件路径及文件名my $p = &quot;$path/$name.$hsize.$vsize.$y.$x.$id.png&quot;;##获取cookie，免除访问实际数据时需要认证my $strcomm = `curl -D $cook -b $cook -d &quot;request=&amp;name=$login&amp;password=$pass&amp;autologin=1&amp;enter=Sign+in&quot; localhost/zabbix/index.php`;##获取图形文件$strcomm = `curl -b $cook -F &quot;graphid=$id&quot; -F &quot;period=$period&quot; -F &quot;stime=$stime&quot; -F &quot;width=$width&quot; -F &quot;height=$height&quot; localhost/zabbix/chart2.php &gt; $p`;&#125;##否则，小于2位的表示是MAPelse &#123;my $p = &quot;$path/map.$name.$id.png&quot;;my $strcomm = `curl -b $cook -F &quot;sysmapid=$id&quot; localhost/zabbix/map.php &gt; $p`; ##ftp到服务器上my $ftp = Net::FTP-&gt;new($FTP_Site,Timeout =&gt; 30) or die &quot;could not connect.\n&quot;;$ftp-&gt;login($ftp_user_name,$ftp_password) or die &quot;Could not login.\n&quot;;$ftp-&gt;binary,$ftp-&gt;message;#$remotefile = &quot;Lync.png&quot;;#$localfile = &quot;$path/$p&quot;;$ftp-&gt;put($p) or die &quot;put $remotefile fail.\n&quot;,$ftp-&gt;message;$ftp-&gt;quit;&#125;&#125;exit ; email-pic.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#! /usr/bin/env pythonimport osimport smtplibfrom email.MIMEMultipart import MIMEMultipartfrom email.MIMEText import MIMETextfrom email.MIMEImage import MIMEImage# 定义函数 _sendmaildef _sendmail(smtp_server,port,account,password,str_from,list_to,msg): smtp = smtplib.SMTP(smtp_server,port) smtp.ehlo() smtp.starttls() smtp.ehlo()# smtp.login(account, password) smtp.sendmail(str_from, list_to,msg) smtp.close() # 定义函数 _get_picturesdef _get_pictures(image_dir):#建立空列表Pictures pictures = []#os.listdir 返回指定目录下的所有文件和目录名 for f in os.listdir(image_dir):# append 是在列表最后增加内容，这里是将list出来的信息f增加到Picture列表中 pictures.append(f) return pictures# 定义函数 _create_msgdef _create_msg(screen_name,screens,image_dir,str_from,list_to): msgRoot = MIMEMultipart('related') # 定义邮件主题 msgRoot['Subject'] = 'Zabbix Screen Report: %s' % screen_name #定义发件人、收件人 msgRoot['From'] = str_from msgRoot['To'] = ",".join(list_to) msgRoot.preamble = 'This is a multi-part message in MIME format.' # Encapsulate the plain and HTML versions of the message body in an # 'alternative' part, so message agents can decide which they want to display. msgAlternative = MIMEMultipart('alternative') msgRoot.attach(msgAlternative)# 定义邮件正文内容 msgText = MIMEText('This is the alternative plain text message.') msgAlternative.attach(msgText) contents = ""# tuple 元组 定义hsize,vsize变量 contents += "&lt;h1&gt;Screen %s&lt;/h1&gt;&lt;br&gt;" % screen_name _,hsize,vsize,_,_,_,_,= tuple(screens[0].split('.')) contents +="&lt;table&gt;" # sorted()是产生一个新的列表并排序 screens = sorted(screens) y= -1 for f in screens:# 将文件名以为.分割点 items = f.split('.') # 原文件名格式:$path/$name.$hsize.$vsize.$y.$x.$id.png# 经过切片后取 image_Y,Image_x,image_ID # tuple 元组 _,_,_,image_y,image_x,image_id,_ = tuple(items) #定义邮件中的图片文件名：image-screen_name-image_id image_name = "image-%s-%s" % (screen_name, image_id) #fp = open("test.txt",w) 直接打开一个文件，如果文件不存在则创建文件 #关于open 模式： #w 以写方式打开， #a 以追加模式打开 (从 EOF 开始, 必要时创建新文件) #r+ 以读写模式打开 #w+ 以读写模式打开 (参见 w ) #a+ 以读写模式打开 (参见 a ) #rb 以二进制读模式打开 #wb 以二进制写模式打开 (参见 w ) #ab 以二进制追加模式打开 (参见 a ) #rb+ 以二进制读写模式打开 (参见 r+ ) #wb+ 以二进制读写模式打开 (参见 w+ ) #ab+ 以二进制读写模式打开 (参见 a+ ) fp = open('%s/%s' % (image_dir,f), 'rb') #fp.read([size]) #size为读取的长度，以byte为单位 msgImage = MIMEImage(fp.read()) #fp.close() #关闭文件。python会在一个文件不用后自动关闭文件，不过这一功能没有保证，最好还是养成自己关闭的习惯。 #如果一个文件在关闭后还对其进行操作会产生ValueError fp.close() msgImage.add_header('Content-ID', "&lt;%s&gt;" % image_name) msgRoot.attach(msgImage)#定义循环 if y != image_y: if y!= -1: contents +="&lt;/tr&gt;" y = image_y contents +="&lt;tr&gt;" # 定义td中嵌套图片文件 contents +="&lt;td&gt;&lt;img src='cid:%s'&gt;&lt;/td&gt;" % image_name # table结束 contents += "&lt;/table&gt;"# 定义邮件格式为HTML msgText = MIMEText(contents, 'html') msgAlternative.attach(msgText)# msgRoot.attach(msgAlternative) return msgRoot# Create the root message and fill in the from, to, and subject headersdef main(str_from,list_to,image_dir): pictures = _get_pictures(image_dir)# 定义screen name,如: Citrix_APP_Server_Loading for screen_name in list(set([x.split('.')[0] for x in pictures ])):# startswith 判断字串开始# screens 是一组 相同前缀的文件,如: screens ['Zabbix_server.2.2.1.1.525.png', 'Zabbix_server.2.2.1.0.524.png'] screens = [x for x in pictures if x.startswith(str(screen_name) + '.') ] msgRoot = _create_msg(screen_name,screens,image_dir,str_from,list_to) #定义邮件服务器地址、端口 _sendmail(smtp_server,port,'','',str_from,list_to,msgRoot.as_string())# 定义发送邮件信息，发件人，收件人，图片目录if __name__ == '__main__': smtp_server = '10.210.1.16' port = 25 str_from = 'adm_zbx@corp.com.cn' list_to = [ "roger.ling@corp.com.cn" ] image_dir = '/data/graph/maps' main(str_from,list_to,image_dir)]]></content>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AWS]]></title>
    <url>%2F2018%2F04%2F25%2FAWS%2F</url>
    <content type="text"><![CDATA[开始使用 Elastic Container Registry构建、标记和推送 Docker 映像现在您的存储库已存在，您可以执行以下步骤推送 Docker 映像: 已成功创建存储库123123123.dkr.ecr.us-east-2.amazonaws.com/asdasd-api 安装 AWS CLI 和 Docker 以及有关以下步骤的更多信息，请访问 ECR 文档页面1) . 检索您可用来对 Docker 客户端进行身份验证以允许其访问注册表的 docker login 命令: aws ecr get-login –no-include-email –region us-east-2 2) 运行上一步中返回的 docker login 命令。 注意：如果您使用的是 Windows PowerShell，请改为运行以下命令。 Invoke-Expression -Command (aws ecr get-login –no-include-email –region us-east-2) 3) 使用以下命令生成 Docker 映像。有关从头开始生成 Docker 文件的信息，请参阅此处的说明。如果您已生成映像，则可跳过此步骤: docker build -t 123123-api . 4) 生成完成后，标记您的映像，以便将映像推送到此存储库: docker tag lucas-api:latest 123123123.dkr.ecr.us-east-2.amazonaws.com/123123-api:latest 5) 运行以下命令将此映像推送到您新创建的 AWS 存储库: docker push 213123123123123.dkr.ecr.us-east-2.amazonaws.com/123123-api:latest]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL自带的性能压力测试工具mysqlslap详解]]></title>
    <url>%2F2018%2F04%2F24%2FMySQL%E8%87%AA%E5%B8%A6%E7%9A%84%E6%80%A7%E8%83%BD%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7mysqlslap%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[查看链接：12345678910mysqladmin -uroot -p1234.com statusUptime: 1370150 Threads: 1 （当前连接数） Questions: 79 Slow queries: 0 Opens: 33 Flush tables: 1 Open tables: 26 Queries per second avg: 0.000mysql -uroot -p1234.com -e &apos;show status&apos; | grep -i Threads Delayed_insert_threads 0Slow_launch_threads 0Threads_cached 1Threads_connected 1Threads_created 2Threads_running 1 ##（当前连接数） 查看最大连接数12mysql -uroot -p1234.com -e &apos;show variables&apos; | grep max_connectionsmax_connections 500 解决方法：想尽一切办法不重启 这种情况一般是进不去数据库了，修改配置文件得重启，对于线上的数据库风险太大了，进入数据库用sql修改，现在是进不去了 方法1： 使用gdb工具 不用进入数据库，不用重启数据库 方法如下： 1gdb -p $(cat /data/mydata/xxx.pid) -ex &quot;set max_connections=500&quot; -batch 查看mysql pid位置的方法 在配置文件 my.cnf里查找 用 ps -ef | grep mysql 查找 1234567mysql&gt; show variables like &apos;%pid%&apos;;+---------------+----------------------+| Variable_name | Value |+---------------+----------------------+| pid_file | /data/mydata/xxx.pid |+---------------+----------------------+1 row in set (0.00 sec) 1修改完毕后 ，尝试重新进入数据库，并查看链接数 这种方法设置后，只是暂时的，数据库重启后，会变为原来的数值，要想永久，设置完后修改配置文件my.cnf 12 方法2 前提是还可以进入数据库 进入数据库 设置新的最大连接数为200：mysql&gt; set GLOBAL max_connections=200 显示当前运行的Query：mysql&gt; show processlist 显示当前状态：mysql&gt; show status 退出客户端：mysql&gt; exit 这种方法设置后，只是暂时的，数据库重启后，会变为原来的数值，要想永久，设置完后修改配置文件my.cnf 方法3： 需要重启数据库 修改 my.conf max_connection = 1000; 模拟mysql连接数过多1234567#!/bin/bashset j=2while true do let &quot;j=j+1&quot;/usr/local/mysql/bin/mysqlslap -a -c 500 -i 10 -uroot -p1234.comdone MySQL自带的性能压力测试工具mysqlslap详解下图是运行mysqlslap -a -c 500 -i 10 -uroot -p123456测试时mysql的连接进程数： 使用语法如下：# mysqlslap [options] 常用参数 [options] 详细说明：–auto-generate-sql, -a 自动生成测试表和数据，表示用mysqlslap工具自己生成的SQL脚本来测试并发压力。 –auto-generate-sql-load-type=type 测试语句的类型。代表要测试的环境是读操作还是写操作还是两者混合的。取值包括：read，key，write，update和mixed(默认)。 –auto-generate-sql-add-auto-increment 代表对生成的表自动添加auto_increment列，从5.1.18版本开始支持。 –number-char-cols=N, -x N 自动生成的测试表中包含多少个字符类型的列，默认1–number-int-cols=N, -y N 自动生成的测试表中包含多少个数字类型的列，默认1–number-of-queries=N 总的测试查询次数(并发客户数×每客户查询次数) –query=name,-q 使用自定义脚本执行测试，例如可以调用自定义的一个存储过程或者sql语句来执行测试。 –create-schema 代表自定义的测试库名称，测试的schema，MySQL中schema也就是database。 –commint=N 多少条DML后提交一次。 –compress, -C 如果服务器和客户端支持都压缩，则压缩信息传递。 –concurrency=N, -c N 表示并发量，也就是模拟多少个客户端同时执行select。可指定多个值，以逗号或者–delimiter参数指定的值做为分隔符。例如：–concurrency=100,200,500。 –engine=engine_name, -e engine_name 代表要测试的引擎，可以有多个，用分隔符隔开。例如：–engines=myisam,innodb。 –iterations=N, -i N 测试执行的迭代次数，代表要在不同并发环境下，各自运行测试多少次。 –only-print 只打印测试语句而不实际执行。 –detach=N 执行N条语句后断开重连。 –debug-info, -T 打印内存和CPU的相关信息。` 说明：测试的过程需要生成测试表，插入测试数据，这个mysqlslap可以自动生成，默认生成一个mysqlslap的schema，如果已经存在则先删除。可以用--only-print来打印实际的测试过程，整个测试完成后不会在数据库中留下痕迹。 各种测试参数实例（-p后面跟的是mysql的root密码）： 测试同时不同的存储引擎的性能进行对比：# mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --engine=myisam,innodb --debug-info -uroot -p123456 执行一次测试，分别50和100个并发，执行1000次总查询：# mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --debug-info -uroot -p123456 50和100个并发分别得到一次测试结果(Benchmark)，并发数越多，执行完所有查询的时间越长。为了准确起见，可以多迭代测试几次:# mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --debug-info -uroot -p123456 实例1说明:测试100个并发线程，测试次数1次，自动生成SQL测试脚本，读、写、更新混合测试，自增长字段，测试引擎为innodb，共运行5000次查询#mysqlslap -h127.0.0.1 -uroot -p123456789 –concurrency=100 –iterations=1 –auto-generate-sql –auto-generate-sql-load-type=mixed –auto-generate-sql-add-autoincrement –engine=innodb –number-of-queries=5000BenchmarkRunning for engine innodbAverage number of seconds to run all queries: 0.351 seconds 100个客户端（并发）同时运行这些SQL语句平均要花0.351秒Minimum number of seconds to run all queries: 0.351 secondsMaximum number of seconds to run all queries: 0.351 secondsNumber of clients running queries: 100 总共100个客户端（并发）运行这些sql查询Average number of queries per client:50 每个客户端（并发）平均运行50次查询（对应–concurrency=100，–number-of-queries=5000；5000/100=50） 实例2#mysqlslap -h127.0.0.1 -uroot -p123456789 –concurrency=100,500,1000 –iterations=1 –auto-generate-sql –auto-generate-sql-load-type=mixed –auto-generate-sql-add-autoincrement –engine=innodb –number-of-queries=5000 –debug-infoBenchmarkRunning for engine innodbAverage number of seconds to run all queries: 0.328 secondsMinimum number of seconds to run all queries: 0.328 secondsMaximum number of seconds to run all queries: 0.328 secondsNumber of clients running queries: 100Average number of queries per client: 50 BenchmarkRunning for engine innodbAverage number of seconds to run all queries: 0.358 secondsMinimum number of seconds to run all queries: 0.358 secondsMaximum number of seconds to run all queries: 0.358 secondsNumber of clients running queries: 500Average number of queries per client: 10 BenchmarkRunning for engine innodbAverage number of seconds to run all queries: 0.482 secondsMinimum number of seconds to run all queries: 0.482 secondsMaximum number of seconds to run all queries: 0.482 secondsNumber of clients running queries: 1000Average number of queries per client: 5 User time 0.21, System time 0.78Maximum resident set size 21520, Integral resident set size 0Non-physical pagefaults 12332, Physical pagefaults 0, Swaps 0Blocks in 0 out 0, Messages in 0 out 0, Signals 0Voluntary context switches 36771, Involuntary context switches 1396 实例3(自定义sql语句)#mysqlslap -h127.0.0.1 -uroot -p123456789 –concurrency=100 –iterations=1 –create-schema=rudao –query=’select * from serverlist;’ –engine=innodb –number-of-queries=5000 –debug-infoBenchmarkRunning for engine innodbAverage number of seconds to run all queries: 0.144 secondsMinimum number of seconds to run all queries: 0.144 secondsMaximum number of seconds to run all queries: 0.144 secondsNumber of clients running queries: 100Average number of queries per client: 50 User time 0.05, System time 0.09Maximum resident set size 6132, Integral resident set size 0Non-physical pagefaults 2078, Physical pagefaults 0, Swaps 0Blocks in 0 out 0, Messages in 0 out 0, Signals 0Voluntary context switches 6051, Involuntary context switches 90 实例4(指定sql脚本)#mysqlslap -h127.0.0.1 -uroot -p123456789 –concurrency=100 –iterations=1 –create-schema=rudao –query=/tmp/query.sql –engine=innodb –number-of-queries=5000 –debug-infoWarning: Using a password on the command line interface can be insecure.BenchmarkRunning for engine innodbAverage number of seconds to run all queries: 0.157 secondsMinimum number of seconds to run all queries: 0.157 secondsMaximum number of seconds to run all queries: 0.157 secondsNumber of clients running queries: 100Average number of queries per client: 50 User time 0.07, System time 0.08Maximum resident set size 6152, Integral resident set size 0Non-physical pagefaults 2107, Physical pagefaults 0, Swaps 0Blocks in 0 out 0, Messages in 0 out 0, Signals 0Voluntary context switches 6076, Involuntary context switches 89]]></content>
  </entry>
  <entry>
    <title><![CDATA[awk sort..]]></title>
    <url>%2F2018%2F04%2F24%2Fawk-sort%2F</url>
    <content type="text"><![CDATA[sort、uniq、awk123456789101112131415161718192021#!/bin/bashSECURE_FILE=/var/log/secureIPS=`tail -n 1000 $SECURE_FILE| grep "Failed password "| egrep -o "([0-9]&#123;1,3&#125;\.)&#123;3&#125;[0-9]&#123;1,3&#125;"| sort -nr|uniq -c| awk '$1&gt;10&#123;print $2&#125;'`IPTABLE_CONF=/etc/sysconfig/iptablescat &lt;&lt;EOFEOFfor ip in echo $IPSdo cat $IPTABLE_CONF | grep $ip&gt;/dev/nulldoneif [ $? -ne 0 ]; then sed -e "/lo/a -A INPUT -s $ip -m state --state NEW -m tcp -p tcp --dport 22 -j DROP" $IPTABLE_CONFelse echo "$ip is in iptables-------do nothing"fiservice iptables restart shell在手分析服务器日志不愁😝1、查看有多少个IP访问： awk ‘{print $1}’ log_file|sort|uniq|wc -l 2、查看某一个页面被访问的次数： grep “/index.php” log_file | wc -l 3、查看每一个IP访问了多少个页面： awk ‘{++S[$1]} END {for (a in S) print a,S[a]}’ log_file &gt; log.txt sort -n -t ‘ ‘ -k 2 log.txt 配合sort进一步排序 4、将每个IP访问的页面数进行从小到大排序： awk ‘{++S[$1]} END {for (a in S) print S[a],a}’ log_file | sort -n 5、查看某一个IP访问了哪些页面： grep ^111.111.111.111 log_file| awk ‘{print $1,$7}’ 6、去掉搜索引擎统计的页面： awk ‘{print $12,$1}’ log_file | grep ^\”Mozilla | awk ‘{print $2}’ |sort | uniq | wc -l 7、查看2015年8月16日14时这一个小时内有多少IP访问: awk ‘{print $4,$1}’ log_file | grep 16/Aug/2015:14 | awk ‘{print $2}’| sort | uniq | wc -l 8、查看访问前十个ip地址 awk ‘{print $1}’ |sort|uniq -c|sort -nr |head -10 access_log uniq -c 相当于分组统计并把统计数放在最前面cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url} 9、访问次数最多的10个文件或页面 12cat log_file|awk &apos;&#123;print 11&#125;&apos;|sort|uniq -c|sort -nr | head -10cat log_file|awk &apos;&#123;print 11&#125;&apos;|sort|uniq -c|sort -nr|head -20awk &apos;&#123;print $1&#125;&apos; log_file |sort -n -r |uniq -c | sort -n -r | head -20 访问量最大的前20个ip 10、通过子域名访问次数，依据referer来计算，稍有不准 cat access.log | awk ‘{print $11}’ | sed -e ‘ s/http:\/\///‘ -e ‘ s/\/.*//‘ | sort | uniq -c | sort -rn | head -20 11、列出传输大小最大的几个文件 cat www.access.log |awk ‘($7~/.php/){print $10 “ “ $1 “ “ $4 “ “ $7}’|sort -nr|head -100 12、列出输出大于200000byte(约200kb)的页面以及对应页面发生次数 cat www.access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 13、如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面 cat www.access.log |awk ‘($7~/.php/){print $NF “ “ $1 “ “ $4 “ “ $7}’|sort -nr|head -100 14、列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat www.access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 15、列出传输时间超过 30 秒的文件 cat www.access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -20 16、列出当前服务器每一进程运行的数量，倒序排列 ps -ef | awk -F ‘ ‘ ‘{print $8 “ “ $9}’ |sort | uniq -c |sort -nr |head -20 17、查看apache当前并发访问数 对比httpd.conf中MaxClients的数字差距多少netstat -an | grep ESTABLISHED | wc -l 18、可以使用如下参数查看数据 ps -ef|grep httpd|wc -l 1388统计httpd进程数，连个请求会启动一个进程，使用于Apache服务器。表示Apache能够处理1388个并发请求，这个值Apache可根据负载情况自动调整 netstat -nat|grep -i “80”|wc -l 4341netstat -an会打印系统当前网络链接状态，而grep -i “80”是用来提取与80端口有关的连接的，wc -l进行连接数统计。最终返回的数字就是当前所有80端口的请求总数 netstat -na|grep ESTABLISHED|wc -l 376netstat -an会打印系统当前网络链接状态，而grep ESTABLISHED 提取出已建立连接的信息。 然后wc -l统计最终返回的数字就是当前所有80端口的已建立连接的总数。 netstat -nat||grep ESTABLISHED|wc 可查看所有建立连接的详细记录 19、输出每个ip的连接数，以及总的各个状态的连接数netstat -n | awk ‘/^tcp/ {n=split($(NF-1),array,”:”);if(n&lt;=2)++S[array[(1)]];else++S[array[(4)]];++s[$NF];++N} END {for(a in S){printf(“%-20s %s\n”, a, S[a]);++I}printf(“%-20s %s\n”,”TOTAL_IP”,I);for(a in s) printf(“%-20s %s\n”,a, s[a]);printf(“%-20s %s\n”,”TOTAL_LINK”,N);}’ 20、其他的收集 分析日志文件下 2012-05-04 访问页面最高 的前20个 URL 并排序 cat access.log |grep ‘04/May/2012’| awk ‘{print $11}’|sort|uniq -c|sort -nr|head -20 查询受访问页面的URL地址中 含有 www.abc.com 网址的 IP 地址 cat access_log | awk ‘($11~/\www.abc.com/){print $1}’|sort|uniq -c|sort -nr 获取访问最高的10个IP地址 同时也可以按时间来查询 cat linewow-access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 时间段查询日志时间段的情况 cat log_file | egrep ‘15/Aug/2015|16/Aug/2015’ |awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 分析2015/8/15 到 2015/8/16 访问”/index.php?g=Member&amp;m=Public&amp;a=sendValidCode”的IP倒序排列 cat log_file | egrep ‘15/Aug/2015|16/Aug/2015’ | awk ‘{if($7 == “/index.php?g=Member&amp;m=Public&amp;a=sendValidCode”) print $1,$7}’|sort|uniq -c|sort -nr ($7~/.php/) $7里面包含.php的就输出,本句的意思是最耗时的一百个PHP页面 cat log_file |awk ‘($7~/.php/){print $NF “ “ $1 “ “ $4 “ “ $7}’|sort -nr|head -100 列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 统计网站流量（G) cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’ 统计404的连接 awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort 统计http status cat access.log |awk ‘{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}’cat access.log |awk ‘{print $9}’|sort|uniq -c|sort -rn 每秒并发 watch “awk ‘{if($9~/200|30|404/)COUNT[$4]++}END{for( a in COUNT) print a,COUNT[a]}’ log_file|sort -k 2 -nr|head -n10” 带宽统计 cat apache.log |awk ‘{if($7~/GET/) count++}END{print “client_request=”count}’cat apache.log |awk ‘{BYTE+=$11}END{print “client_kbyte_out=”BYTE/1024”KB”}’ 找出某天访问次数最多的10个IP cat /tmp/access.log | grep “20/Mar/2011” |awk ‘{print $3}’|sort |uniq -c|sort -nr|head 当天ip连接数最高的ip都在干些什么 cat access.log | grep “10.0.21.17” | awk ‘{print $8}’ | sort | uniq -c | sort -nr | head -n 10 小时单位里ip连接数最多的10个时段 awk -vFS=”[:]” ‘{gsub(“-.*”,””,$1);num[$2” “$1]++}END{for(i in num)print i,num[i]}’ log_file | sort -n -k 3 -r | head -10 找出访问次数最多的几个分钟 awk ‘{print $1}’ access.log | grep “20/Mar/2011” |cut -c 14-18|sort|uniq -c|sort -nr|head取5分钟日志if [ $DATE_MINUTE != $DATE_END_MINUTE ] ;then #则判断开始时间戳与结束时间戳是否相等START_LINE=sed -n “/$DATE_MINUTE/=” $APACHE_LOG|head -n1 #如果不相等，则取出开始时间戳的行号，与结束时间戳的行号 查看tcp的链接状态 netstat -nat |awk ‘{print $6}’|sort|uniq -c|sort -rn netstat -n | awk ‘/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}’ netstat -n | awk ‘/^tcp/ {++state[$NF]}; END {for(key in state) print key,”\t”,state[key]}’ netstat -n | awk ‘/^tcp/ {++arr[$NF]};END {for(k in arr) print k,”\t”,arr[k]}’ netstat -n |awk ‘/^tcp/ {print $NF}’|sort|uniq -c|sort -rn netstat -ant | awk ‘{print $NF}’ | grep -v ‘[a-z]’ | sort | uniq -cnetstat -ant|awk ‘/ip:80/{split($5,ip,”:”);++S[ip[1]]}END{for (a in S) print S[a],a}’ |sort -n netstat -ant|awk ‘/:80/{split($5,ip,”:”);++S[ip[1]]}END{for (a in S) print S[a],a}’ |sort -rn|head -n 10 awk ‘BEGIN{printf (“http_code\tcount_num\n”)}{COUNT[$10]++}END{for (a in COUNT) printf a”\t\t”COUNT[a]”\n”}’查找请求数前20个IP（常用于查找攻来源）：netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20netstat -ant |awk ‘/:80/{split($5,ip,”:”);++A[ip[1]]}END{for(i in A) print A[i],i}’ |sort -rn|head -n20 用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F”.” ‘{print $1”.”$2”.”$3”.”$4}’ | sort | uniq -c | sort -nr |head -20 查找较多time_wait连接 netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n20 找查较多的SYN连接 netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more 根据端口列进程netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1 查看了连接数和当前的连接数 netstat -ant | grep $ip:80 | wc -lnetstat -ant | grep $ip:80 | grep EST | wc -l 查看IP访问次数netstat -nat|grep “:80”|awk ‘{print $5}’ |awk -F: ‘{print $1}’ | sort| uniq -c|sort -n Linux命令分析当前的链接状况netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’ watch “netstat -n | awk ‘/^tcp/ {++S[\$NF]} END {for(a in S) print a, S[a]}’” # 通过watch可以一直监控 LAST_ACK 5 #关闭一个TCP连接需要从两个方向上分别进行关闭，双方都是通过发送FIN来表示单方向数据的关闭，当通信双方发送了最后一个FIN的时候，发送方此时处于LAST_ACK状态，当发送方收到对方的确认（Fin的Ack确认）后才真正关闭整个TCP连接； SYN_RECV 30 # 表示正在等待处理的请求数； ESTABLISHED 1597 # 表示正常数据传输状态； FIN_WAIT1 51 # 表示server端主动要求关闭tcp连接； FIN_WAIT2 504 # 表示客户端中断连接； TIME_WAIT 1057 # 表示处理完毕，等待超时结束的请求数；]]></content>
  </entry>
  <entry>
    <title><![CDATA[ORACLE链接问题]]></title>
    <url>%2F2018%2F04%2F17%2FORACLE%E9%93%BE%E6%8E%A5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[ORACLE链接问题找不到动态库ldd sqlplusecho $LD_LIBRARY_PATHexport $LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib ORA-21561: OID generation failed修改/etc/hosts文件，追加本机map，否则会报””错误 #vi /etc/hosts 追加如下信息： 192.168.1.171 centos62 其中centos62为本机主机名，可以通过hostname命令查看]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2018%2F04%2F17%2FAnsible%2F</url>
    <content type="text"><![CDATA[ansible使用记录Ansible 安装教程ansible 的安装轻而易举，许多发行版的第三方软件仓库中都有现成的软件包，可以直接安装。其他简单的安装方法包括使用 pip 安装它，或者从 github 里获取最新的版本。若想使用你的软件包管理器安装，在基于 RHEL/CentOS Linux 的系统里你很可能需要 EPEL 仓库。 在基于 RHEL/CentOS Linux 的系统中安装 ansible输入如下 yum 命令: 1$ sudo yum install ansible 在基于 Debian/Ubuntu Linux 的系统中安装 ansible输入如下 apt-get 命令: 1$ sudo apt-get install software-properties-common$ sudo apt-add-repository ppa:ansible/ansible$ sudo apt-get update$ sudo apt-get install ansible 使用 pip 安装 ansiblepip 命令是一个安装和管理 Python 软件包的工具，比如它能管理 Python Package Index 中的那些软件包。如下方式在 Linux 和类 Unix 系统中通用： 1$ sudo pip install ansible 从源代码安装最新版本的 ansible你可以通过如下命令从 github 中安装最新版本： 1$ cd ~$ git clone git://github.com/ansible/ansible.git$ cd ./ansible$ source ./hacking/env-setup 当你从一个 git checkout 中运行 ansible 的时候，请记住你每次用它之前都需要设置你的环境，或者你可以把这个设置过程加入你的 bash rc 文件中： 1# 加入 BASH RC$ echo &quot;export ANSIBLE_HOSTS=~/ansible_hosts&quot; &gt;&gt; ~/.bashrc$ echo &quot;source ~/ansible/hacking/env-setup&quot; &gt;&gt; ~/.bashrc ansible 的 hosts 文件包括了一系列它能操作的主机。默认情况下 ansible 通过路径 /etc/ansible/hosts 查找 hosts 文件，不过这个行为也是可以更改的，这样当你想操作不止一个 ansible 或者针对不同的数据中心的不同客户操作的时候也是很方便的。你可以通过命令行参数 -i 指定 hosts 文件： 1$ ansible all -m shell -a &quot;hostname&quot; --ask-pass -i /etc/some/other/dir/ansible_hosts 不过我更倾向于使用一个环境变量，这可以在你想要通过 source 一个不同的文件来切换工作目标的时候起到作用。这里的环境变量是 $ANSIBLE_HOSTS，可以这样设置： 1$ export ANSIBLE_HOSTS=~/ansible_hosts 一旦所有需要的组件都已经安装完毕，而且你也准备好了你的 hosts 文件，你就可以来试一试它了。为了快速测试，这里我把 127.0.0.1 写到了 ansible 的 hosts 文件里： 1$ echo &quot;127.0.0.1&quot; &gt; ~/ansible_hosts 现在来测试一个简单的 ping： 1$ ansible all -m ping 或者提示 ssh 密码： 1$ ansible all -m ping --ask-pass 我在刚开始的设置中遇到过几次问题，因此这里强烈推荐为 ansible 设置 SSH 公钥认证。不过在刚刚的测试中我们使用了 –ask-pass，在一些机器上你会需要安装 sshpass 或者像这样指定 -c paramiko： 1$ ansible all -m ping --ask-pass -c paramiko 当然你也可以安装 sshpass，然而 sshpass 并不总是在标准的仓库中提供，因此 paramiko 可能更为简单。 设置 SSH 公钥认证于是我们有了一份配置，以及一些基础的其他东西。现在让我们来做一些实用的事情。ansible 的强大很大程度上体现在 playbooks 上，后者基本上就是一些写好的 ansible 脚本（大部分来说），不过在制作一个 playbook 之前，我们将先从一些一句话脚本开始。现在让我们创建和配置 SSH 公钥认证，以便省去 -c 和 –ask-pass 选项： 1$ ssh-keygen -t rsa 现在显然有很多种方式来把它放到远程主机上应该的位置。不过既然我们正在使用 ansible，就用它来完成这个操作吧： 1$ ansible all -m copy -a &quot;src=/home/xxx/.ssh/id_rsa.pub dest=/tmp/id_rsa.pub&quot; --ask-pass -c paramiko 下一步，把公钥文件添加到远程服务器里。输入： 1$ ansible all -m shell -a &quot;cat /tmp/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys&quot; --ask-pass -c paramiko 样例输出： 1SSH password:127.0.0.1 | FAILED | rc=1 &gt;&gt;/bin/sh: /root/.ssh/authorized_keys: Permission denied 矮油，我们需要用 root 来执行这个命令，所以还是加上一个 -u 参数吧： 1$ ansible all -m shell -a &quot;cat /tmp/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys&quot; --ask-pass -c paramiko -u root 样例输出： 1SSH password:127.0.0.1 | success | rc=0 &gt;&gt; 请注意，我刚才这是想要演示通过 ansible 来传输文件的操作。事实上 ansible 有一个更加方便的内置 SSH 密钥管理支持： 1$ ansible all -m authorized_key -a &quot;user=xxx key=&apos;&#123;&#123; lookup(&apos;file&apos;, &apos;/home/xxx/.ssh/id_rsa.pub&apos;) &#125;&#125;&apos; path=/home/xxx/.ssh/authorized_keys manage_dir=no&quot; --ask-pass -c paramiko 现在这些密钥已经设置好了。我们来试着随便跑一个命令，比如 hostname，希望我们不会被提示要输入密码 1$ ansible all -m shell -a &quot;hostname&quot; -u root 样例输出： 1127.0.0.1 | success | rc=0 &gt;&gt; 成功！！！现在我们可以用 root 来执行命令，并且不会被输入密码的提示干扰了。我们现在可以轻易地配置任何在 ansible hosts 文件中的主机了。让我们把 /tmp 中的公钥文件删除： 1$ ansible all -m file -a &quot;dest=/tmp/id_rsa.pub state=absent&quot; -u root 样例输出： 1127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: true, &quot;path&quot;: &quot;/tmp/id_rsa.pub&quot;, &quot;state&quot;: &quot;absent&quot;&#125; 下面我们来做一些更复杂的事情，我要确定一些软件包已经安装了，并且已经是最新的版本： 1$ ansible all -m zypper -a &quot;name=apache2 state=latest&quot; -u root 样例输出： 1127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;name&quot;: &quot;apache2&quot;, &quot;state&quot;: &quot;latest&quot;&#125; 很好，我们刚才放在 /tmp 中的公钥文件已经消失了，而且我们已经安装好了最新版的 apache。下面我们来看看前面命令中的 -m zypper，一个让 ansible 非常灵活，并且给了 playbooks 更多能力的功能。如果你不使用 openSuse 或者 Suse enterprise 你可能还不熟悉 zypper, 它基本上就是 suse 世界中相当于 yum 的存在。在上面所有的例子中，我的 hosts 文件中都只有一台机器。除了最后一个命令外，其他所有命令都应该在任何标准的 *nix 系统和标准的 ssh 配置中使用，这造成了一个问题。如果我们想要同时管理多种不同的机器呢？这便是 playbooks 和 ansible 的可配置性闪闪发光的地方了。首先我们来少许修改一下我们的 hosts 文件： 1$ cat ~/ansible_hosts 样例输出： 12[RHELBased]121.12.12.12[SUSEBased]127.0.0.1 首先，我们创建了一些分组的服务器，并且给了他们一些有意义的标签。然后我们来创建一个为不同类型的服务器执行不同操作的 playbook。你可能已经发现这个 yaml 的数据结构和我们之前运行的命令行语句中的相似性了。简单来说，-m 是一个模块，而 -a 用来提供模块参数。在 YAML 表示中你可以先指定模块，然后插入一个冒号 :，最后指定参数。 12345678910111213---- hosts: SUSEBased remote_user: root tasks: - zypper: name=apache2 state=latest- hosts: RHELBased remote_user: root tasks: - yum: name=httpd state=latest 现在我们有一个简单的 playbook 了，我们可以这样运行它： 1$ ansible-playbook testPlaybook.yaml -f 10 注意，你会看到 ansible 联系到的每一台机器的输出。-f 参数让 ansible 在多台主机上同时运行指令。除了指定全部主机，或者一个主机分组的名字以外，你还可以把导入 ssh 公钥的操作从命令行里转移到 playbook 中，这将在设置新主机的时候提供很大的方便，甚至让新主机直接可以运行一个 playbook。为了演示，我们把我们之前的公钥例子放进一个 playbook 里： 1234567891011121314151617---- hosts: SUSEBased remote_user: xxx sudo: yes tasks: - authorized_key: user=root key=&quot;&#123;&#123; lookup(&apos;file&apos;, &apos;/home/xxx/.ssh/id_rsa.pub&apos;) &#125;&#125;&quot; path=/root/.ssh/authorized_keys manage_dir=no- hosts: RHELBasedremote_user: aaa sudo: yes tasks: - authorized_key: user=root key=&quot;&#123;&#123; lookup(&apos;file&apos;, &apos;/home/xxx/.ssh/id_rsa.pub&apos;) &#125;&#125;&quot; path=/root/.ssh/authorized_keys manage_dir=no 除此之外还有很多可以做的事情，比如在启动的时候把公钥配置好，或者引入其他的流程来让你按需配置一些机器。不过只要 SSH 被配置成接受密码登陆，这些几乎可以用在所有的流程中。在你准备开始写太多 playbook 之前，另一个值得考虑的事情是，代码管理可以有效节省你的时间。机器需要不断变化，然而你并不需要在每次机器发生变化时都重新写一个 playbook，只需要更新相关的部分并提交这些修改。与此相关的另一个好处是，如同我之前所述，你可以从不同的地方管理你的整个基础结构。你只需要将你的 playbook 仓库 git clone 到新的机器上，就完成了管理所有东西的全部设置流程。 现实中的 ansible 例子我知道很多用户经常使用 pastebin 这样的服务，以及很多公司基于显而易见的理由配置了他们内部使用的类似东西。最近，我遇到了一个叫做 showterm 的程序，巧合之下我被一个客户要求配置它用于内部使用。这里我不打算赘述这个应用程序的细节，不过如果你感兴趣的话，你可以使用 Google 搜索 showterm。作为一个合理的现实中的例子，我将会试图配置一个 showterm 服务器，并且配置使用它所需要的客户端应用程序。在这个过程中我们还需要一个数据库服务器。现在我们从配置客户端开始： 1234567891011121314151617---- hosts: showtermClients remote_user: root tasks: - yum: name=rubygems state=latest - yum: name=ruby-devel state=latest - yum: name=gcc state=latest - gem: name=showterm state=latest user_install=no 这部分很简单。下面是主服务器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485---- hosts: showtermServers remote_user: root tasks: - name: ensure packages are installed yum: name=&#123;&#123;item&#125;&#125; state=latest with_items: - postgresql - postgresql-server - postgresql-devel - python-psycopg2 - git - ruby21 - ruby21-passenger - name: showterm server from github git: repo=https://github.com/ConradIrwin/showterm.io dest=/root/showterm- name: Initdb command: service postgresql initdb creates=/var/lib/pgsql/data/postgresql.conf - name: Start PostgreSQL and enable at boot service: name=postgresql enabled=yes state=started - gem: name=pg state=latest user_install=no handlers: - name: restart postgresql service: name=postgresql state=restarted - hosts: showtermServers remote_user: root sudo: yes sudo_user: postgres vars: dbname: showterm dbuser: showterm dbpassword: showtermpassword tasks: - name: create db postgresql_db: name=&#123;&#123;dbname&#125;&#125; - name: create user with ALL priv postgresql_user: db=&#123;&#123;dbname&#125;&#125; name=&#123;&#123;dbuser&#125;&#125; password=&#123;&#123;dbpassword&#125;&#125; priv=ALL- hosts: showtermServers remote_user: root tasks: - name: database.yml template: src=database.yml dest=/root/showterm/config/database.yml- hosts: showtermServers remote_user: root tasks: - name: run bundle install shell: bundle install args: chdir: /root/showterm- hosts: showtermServers remote_user: root tasks: - name: run rake db tasks shell: &apos;bundle exec rake db:create db:migrate db:seed&apos; args:chdir: /root/showterm- hosts: showtermServers remote_user: root tasks: - name: apache config template: src=showterm.conf dest=/etc/httpd/conf.d/showterm.conf 还凑合。请注意，从某种意义上来说这是一个任意选择的程序，然而我们现在已经可以持续地在任意数量的机器上部署它了，这便是配置管理的好处。此外，在大多数情况下这里的定义语法几乎是不言而喻的，wiki 页面也就不需要加入太多细节了。当然在我的观点里，一个有太多细节的 wiki 页面绝不会是一件坏事。 扩展配置我们并没有涉及到这里所有的细节。Ansible 有许多选项可以用来配置你的系统。你可以在你的 hosts 文件中内嵌变量，而 ansible 将会把它们应用到远程节点。如： 12345[RHELBased]9.9.9.9. http_port=443 8.8.8.8 http_port=80 ansible_ssh_user=mdonlon [SUSEBased]127.0.0.1 http_port=443 尽管这对于快速配置来说已经非常方便，你还可以将变量分成存放在 yaml 格式的多个文件中。在你的 hosts 文件路径里，你可以创建两个子目录 groupvars 和 hostvars。在这些路径里放置的任何文件，只要能对得上一个主机分组的名字，或者你的 hosts 文件中的一个主机名，它们都会在运行时被插入进来。所以前面的一个例子将会变成这样： 12345678910ultrabook:/etc/ansible # pwd/etc/ansibleultrabook:/etc/ansible # tree.├── group_vars│ ├── RHELBased│ └── SUSEBased├── hosts└── host_vars ├── 10.50.1.33 └── 10.50.1.47 1234567891011121314151617182 directories, 5 filesultrabook:/etc/ansible # cat hosts[RHELBased]10.50.1.3310.50.1.47[SUSEBased]127.0.0.1ultrabook:/etc/ansible # cat group_vars/RHELBasedultrabook:/etc/ansible # cat group_vars/SUSEBased---http_port: 443ultrabook:/etc/ansible # cat host_vars/10.50.1.33---http_port: 443ultrabook:/etc/ansible # cat host_vars/10.50.1.47---http_port:80ansible_ssh_user: mdonlon 改善 Playbooks组织 playbooks 也已经有很多种现成的方式。在前面的例子中我们用了一个单独的文件，因此这方面被大幅地简化了。组织这些文件的一个常用方式是创建角色。简单来说，你将一个主文件加载为你的 playbook，而它将会从其它文件中导入所有的数据，这些其他的文件便是角色。举例来说，如果你有了一个 wordpress 网站，你需要一个 web 前端，和一个数据库。web 前端将包括一个 web 服务器，应用程序代码，以及任何需要的模块。数据库有时候运行在同一台主机上，有时候运行在远程的主机上，这时候角色就可以派上用场了。你创建一个目录，并对每个角色创建对应的小 playbook。在这个例子中我们需要一个 apache 角色，mysql 角色，wordpress 角色，mod_php，以及 php 角色。最大的好处是，并不是每个角色都必须被应用到同一台机器上。在这个例子中，mysql 可以被应用到一台单独的机器。这同样为代码重用提供了可能，比如你的 apache 角色还可以被用在 python 和其他相似的 php 应用程序中。展示这些已经有些超出了本文的范畴，而且做一件事总是有很多不同的方式，我建议搜索一些 ansible 的 playbook 例子。有很多人在 github 上贡献代码，当然还有其他一些网站。 ansible命令集：/usr/bin/ansible: # Ansibe AD-Hoc 临时命令执行工具，常用于临时命令的执行/usr/bin/ansible-doc: # Ansible 模块功能查看工具/usr/bin/ansible-galaxy: # 下载/上传优秀代码或Roles模块的官网平台，基于网络的/usr/bin/ansible-playbook: # Ansible 定制自动化的任务集编排工具/usr/bin/ansible-pull: # Ansible远程执行命令的工具（使用较少，海量机器时使用，对运维的架构能力要求较高）/usr/bin/ansible-vault: # Ansible 文件加密工具/usr/bin/ansible-console: # Ansible基于Linux Consoble界面可与用户交互的命令执行工具/usr/share/ansible_plugins:Ansible高级自定义插件目录（需要python基础）/etc/ansible/ansible.cfg:配置文件/etc/ansible/hosts:主机清单 Ansible 配置文件 绝大多数配置保持默认就好1）[defaults] 123456789101112131415#inventory = /etc/ansible/hosts # 主机列表配置文件#library = /usr/share/my_modules/ # 库文件存放目录 #remote_tmp = $HOME/.ansible/tmp # 生成的临时py命令文件存放在远程主机的目录#local_tmp = $HOME/.ansible/tmp # 本机的临时命令执行目录#forks = 5 # 默认并发数#poll_interval = 15 # 默认的线程池#sudo_user = root # 默认sudo 用户#ask_sudo_pass = True#ask_pass = True#transport = smart#remote_port = 22#module_lang = C#module_set_locale = Falsehost_key_checking = False ### 检查对应服务器的host_key （2）[privilege_escalation]（3）[paramiko_connection]（4）[ssh_connection]（5）[accelerate]（6）[selinux]（7）[colors] Ansible命令使用说明ansible1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#调用ping模块检测node3主机是否存活（node2,3,4能基于主机名通信，且已做过免密钥通信） [root@node2 ~/.ssh]# ansible node3 -m ping node3 | success &gt;&gt; &#123; "changed": false, "ping": "pong" &#125;[root@node2 ~/.ssh]# root@node2 ~/.ssh]# ansible -h Usage: ansible &lt;host-pattern&gt; [options]Options: -a MODULE_ARGS, --args=MODULE_ARGS #模块的参数,如果执行默认COMMAND的模块，即是命令参数,如：“date”,"pwd"等等 module arguments #模块参数 --ask-become-pass ask for privilege escalation password # Ansible su切换用户的时候使用该参数输入密码 -k, --ask-pass ask for SSH password #登录密码，提示输入SSH密码而不是假设基于密钥的验证 --ask-su-pass ask for su password #su切换密码 -K, --ask-sudo-pass ask for sudo password #提示密码使用sudo,sudo表示提权操作 --ask-vault-pass ask for vault password # ansible-valut 加密文件 -B SECONDS, --background=SECONDS #后台运行超时时间 run asynchronously, failing after X seconds (default=N/A) -C, --check don't make any changes; instead, try to predict some #只是测试一下会改变什么内容，不会真正去执行;相反,试图预测一些可能发生的变化 of the changes that may occur -c CONNECTION, --connection=CONNECTION 连接类型使用。可能的选项是paramiko(SSH),SSH和地方。当地主要是用于crontab或启动。 connection type to use (default=smart) -e EXTRA_VARS, --extra-vars=EXTRA_VARS # 调用外部变量 -f FORKS, --forks=FORKS # Ansible一次命令执行并发的线程数,默认是5 specify number of parallel processes to use (default=5) -h, --help show this help message and exit #打开帮助文档API -i INVENTORY, --inventory-file=INVENTORY #指定库存主机文件的路径,默认为/etc/ansible/hosts specify inventory host file (default=/etc/ansible/hosts) -l SUBSET, --limit=SUBSET #进一步限制所选主机/组模式 --limit=192.168.91.135 只对这个ip执行 further limit selected hosts to an additional pattern --list-hosts outputs a list of matching hosts; does not execute anything else -m MODULE_NAME, --module-name=MODULE_NAME #执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数 module name to execute (default=command) -M MODULE_PATH, --module-path=MODULE_PATH #要执行的模块的路径，默认为/usr/share/ansible/ specify path(s) to module library (default=/usr/share/ansible/) -o, --one-line condense output #压缩输出，摘要输出.尝试一切都在一行上输出。 -P POLL_INTERVAL, --poll=POLL_INTERVAL #调查背景工作每隔数秒。需要- b set the poll interval if using -B (default=15) --private-key=PRIVATE_KEY_FILE #私钥路径，使用这个文件来验证连接 use this file to authenticate the connection -S, --su run operations with su 用 su 命令 -R SU_USER, --su-user=SU_USER #指定SU的用户，默认是root用户 run operations with su as this user (default=root) -s, --sudo run operations with sudo (nopasswd) -U SUDO_USER, --sudo-user=SUDO_USER #sudo到哪个用户，默认为 root desired sudo user (default=root) -T TIMEOUT, --timeout=TIMEOUT #指定SSH默认超时时间， 默认是10S override the SSH timeout in seconds (default=10) -t TREE, --tree=TREE log output to this directory #将日志内容保存在该输出目录,结果保存在一个文件中在每台主机上。 -u REMOTE_USER, --user=REMOTE_USER #远程用户， 默认是root用户 connect as this user (default=root) --vault-password-file=VAULT_PASSWORD_FILE vault password file -v, --verbose verbose mode (-vvv for more, -vvvv to enable 详细信息 connection debugging) --version show program's version number and exit #输出ansible的版本 Ansiblie命令执行过程 （-vvvv）加载自己的配置文件 默认/etc/ansible/ansible.cfg加载自己对应的模块文件，如command通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的 对应执行用户的家目录的.ansible/tmp/XXX/XXX.PY文件给文件+x执行执行并返回结果删除临时py文件，sleep 0退出 ansible主机清单的配置 /ect/ansible/hosts,定义方式： 直接指明主机地址或主机名node3 172.16.47.104定义一个主机组，把主机地址或主机名写进去，然后通过组名来调用这个组[webservers] node3node4如果没有使用公钥，想要使用密码，也可以这样写（适用于第一次登陆控制）格式：【主机名】 【主机地址】 【主机密码】 默认是root用户来进行的 [keepalived] keepalived1 ansible_ssh_host=192.168.146.136 ansible_ssh_pass=”test” keepalived2 ansible_ssh_host=192.168.146.137 ansible_ssh_pass=”test” 10.0.1.5 ansible_ssh_private_key_file=ssh_keys/10.0.1.5.key ansible_ssh_user=rootansible-doc ansible-doc -l :获取模块信息 ansible-doc -s MOD_NAME: 获取指定模块的使用帮助1234567891011[root@node2 ~]# ansible-doc -h Usage: ansible-doc [options] [module...]Show Ansible module documentation 显示Ansible模块文档Options: --version show program&apos;s version number and exit 显示ansible-doc的版本号 -h, --help show this help message and exit 显示命令参数API文档 -M MODULE_PATH, --module-path=MODULE_PATH 查询模块，--module-path=MODULE_PATH 指定模块的路径 Ansible modules/ directory -l, --list List available modules 显示已存在的所有模块列表 -s, --snippet Show playbook snippet for specified module(s) 显示playbook制定模块的用法 -v Show version number and exit 显示ansible-doc的版本号 Ansible模块command模块:使用ansible自带模块执行命令 如果要用 &gt; &lt; | &amp; ‘ ‘ 使用shell模块 12345678[root@node2 ~/.ssh]# ansible all -m command -a &quot;ls /root/.ssh&quot; node4 | success | rc=0 &gt;&gt;authorized_keysknown_hostsnode3 | success | rc=0 &gt;&gt;authorized_keysknown_hosts[root@node2 ~/.ssh]# 相关选项如下： creates：一个文件名，当该文件存在，则该命令不执行free_form：要执行的linux指令chdir：在执行指令之前，先切换到该目录removes：一个文件名，当该文件不存在，则该选项不执行executable：切换shell来执行指令，该执行路径必须是一个绝对路径 shell 模块:调用bash执行命令 类似 cat /tmp/stanley.md | awk -F’|’ ‘{print $1,$2}’ &amp;&gt; /tmp/stanley.txt 这些复杂命令，即使使用shell也会失败，解决办法：写到脚本时，copy到远程，执行，再把需要的结果拉回执行命令的机器（执行Ansible命令的机器往往称为：Master机或者中控机或者堡垒机）。 注意：command和shell模块的核心参数直接为命令本身；而其它模块的参数通常为“key=value”格式；’’ copy模块：复制本地文件至远程服务器，并且能够改属性等 直接复制： 1ansible all -m copy -a &quot;src=txt dest=/tmp mode=540&quot; 生成内容的复制： 12ansible all -m copy -a &quot;content=&apos;hellow&apos; dest=/tmp/test mode=540&quot;ansible all -m shell -a &quot;cat /tmp/test mode=540&quot; 注意：这两种方法是互斥的，即src和content不能同时使用相关选项如下： backup：在覆盖之前，将源文件备份，备份文件包含时间信息。有两个选项：yes|nocontent：用于替代“src”，可以直接设定指定文件的值dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录directory_mode：递归设定目录的权限，默认为系统默认权限force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yesothers：所有的file模块里的选项都可以在这里使用src：被复制到远程主机的本地文件，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用“/”来结尾，则只复制目录里的内容，如果没有使用“/”来结尾，则包含目录在内的整个内容全部复制，类似于rsync。 file模块：设置文件属性 -a “path=PATH state=directory” # 创建目录 ~]# ansible all -m file -a "path12 -a “path=PATH src=FILE state=link” #创建链接文件 [root@node2 ~]# ansible all -m file -a “path=/root/haha src=/tmp/hehe state=link” -a “path=PATH state=absent” #删除文件[root@node2 ~]# ansible all -m file -a “path=/root/haha state=absent” 相关选项如下：force：需要在两种情况下强制创建软链接，一种是源文件不存在，但之后会建立的情况下；另一种是目标软链接已存在，需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no group：定义文件/目录的属组mode：定义文件/目录的权限owner：定义文件/目录的属主path：必选项，定义文件/目录的路径recurse：递归设置文件的属性，只对目录有效 src：被链接的源文件路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，就创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 fetch模块： 从远程服务器拉取文件至本机，只能fetch文件，不能fetch目录,如果拉目录，先tar/zip 再拉到本机即可 [root@node2 ~]# ansible all -m fetch -a “src=/tmp/txt dest=/root/txt.txt” cron模块: 管理cron计划任务 [root@node2 ~]# ansible all -m corn -a “minute=’*/5’ job=’/usr/sbin/ntpdate 172.16.0.1 &amp;&gt; /dev/null’ name=’Synctime’” #每5分钟同步一下时间 [root@node2 ~]# ansible all -m corn -a “state=absent name=’Synctime’” #删除上面的定时任务 相关选项如下： a “”: 设置管理节点生成定时任务 action: cron backup= # 如果设置，创建一个crontab备份 cron_file= #如果指定, 使用这个文件cron.d，而不是单个用户crontab day= # 日应该运行的工作( 1-31, , /2, etc ) hour= # 小时 ( 0-23, , /2, etc ) job= #指明运行的命令是什么 minute= #分钟( 0-59, , /2, etc ) month= # 月( 1-12, , /2, etc ) name= #定时任务描述 reboot # 任务在重启时运行，不建议使用，建议使用special_time special_time # 特殊的时间范围，参数：reboot（重启时）,annually（每年）,monthly（每月）,weekly（每周）,daily（每天）,hourly（每小时） state #指定状态，prsent表示添加定时任务，也是默认设置，absent表示删除定时任务 user # 以哪个用户的身份执行 weekday # 周 ( 0-6 for Sunday-Saturday, *, etc ) yum模块：yum安装软件，也有apt,zypper [root@node2 ~]# ansible all -m yum -a “name=httpd state=latest” #安装httpd包 相关选项如下： conf_file #设定远程yum安装时所依赖的配置文件。如配置文件没有在默认的位置。 disable_gpg_check #是否禁止GPG checking，只用于present&#39; orlatest’。 disablerepo #临时禁止使用yum库。 只用于安装或更新时。 enablerepo #临时使用的yum库。只用于安装或更新时。 name= #所安装的包的名称 state #present安装， latest安装最新的, absent 卸载软件。 update_cache #强制更新yum的缓存。 service模块: 服务程序管理 [root@node2 ~]# ansible all -m service -a “name=httpd state=restarted” #重启httpd [root@node2 ~]# ansible all -m service -a “name=httpd enabled=true” #开机启动 相关选项如下： arguments #命令行提供额外的参数 enabled #设置开机启动。 name= #服务名称 runlevel #开机启动的级别，一般不用指定。 sleep #在重启服务的过程中，是否等待。如在服务关闭以后等待2秒再启动。 state #started启动服务， stopped停止服务， restarted重启服务，&gt; group模块: 组管理 [root@node2 ~]# ansible-doc -s group name: 添加或删除组 action: group gid # 设置组的GID号 name= # 管理组的名称 state # 指定组状态，默认为创建，设置值为absent为删除 system # 设置值为yes，表示为创建系统组 User模块:用户管理 -a “” action: user comment # 用户的描述信息 createhom # 是否创建家目录 force # 在使用state=absent&#39;是, 行为与userdel –force’一致. group # 指定基本组 groups # 指定附加组，如果指定为(‘groups=’)表示删除所有组 home # 指定用户家目录 login_class #可以设置用户的登录类 FreeBSD, OpenBSD and NetBSD系统. move_home # 如果设置为home=&#39;时, 试图将用户主目录移动到指定的目录 name= # 指定用户名 non_unique # 该选项允许改变非唯一的用户ID值 password # 指定用户密码 remove # 在使用state=absent’时, 行为是与 `userdel –remove’一致. shell # 指定默认shell state #设置帐号状态，不指定为创建，指定值为absent表示删除 system # 当创建一个用户，设置这个用户是系统用户。这个设置不能更改现有用户。 uid #指定用户的uidupdate_password # 更新用户密码expires #指明密码的过期时间ansible all -m user -a ‘name=magedu home=/tmp/magedu/ shell=/bin/bash uid=2000 comment=”test user” group=root’ ping 模块： 检测主机存活 setup模块：获取指定主机的facts。 facts就是变量，内建变量 。每个主机的各种信息，cpu颗数、内存大小等。会存在facts中的某个变量中。调用后返回很多对应主机的信息，在后面的操作中可以根据不同的信息来做不同的操作。如redhat系列用yum安装，而debian系列用apt来安装软件。 ansible node3 -m setup selinux模块： 管理selinux 关闭selinux ansible all -m selinux -a ‘state=disabled’ conf #指定应用selinux的配置文件。 state=enforcing|permissive|disabled #对应于selinux配置文件的SELINUX。 policy=targeted|minimum|mls #对应于selinux配置文件的SELINUXTYPE script模块：发送脚本到各被管理节点，并执行;不需要参数 ansible all -m script -a ‘test.sh’ #直接在-a 后面指定脚本即可 未完待续…… 最后打个广告，Stanley老师的Ansible权威指南，你，值得拥有 DSC0007.png (64.81 KB, 下载次数: 0) 下载附件 保存到相册 2017-6-9 08:59 上传]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F04%2F16%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment ＣＮＡＭＥ1$ echo "blog.lucas.space"&gt;source/CNAME]]></content>
  </entry>
  <entry>
    <title><![CDATA[OCi8 on php]]></title>
    <url>%2F2018%2F04%2F13%2FOCi8-on-php%2F</url>
    <content type="text"><![CDATA[php with OCI8使用php的常见问题是：编译php时忘记添加某扩展，后来想添加扩展，但是因为安装php后又装了一些东西如PEAR等，不想删除目录重装，那么此时就需要自己重新增加某模块支持了,Linux操作系统下可以用phpize给PHP动态添加扩展.下面就以扩展模块 oci8为例(php连接oracle数据库需要改扩展支持)做简单的说明 下载Oracle客户端程序包，其中包含OCI、OCCI和JDBC-OCI等相关文件 1.1 根据Linux系统选择对应的软件,以32位系统为例,所以下载如下文件: oracle-instantclient11.2-basic-11.2.0.3.0-1.i386.rpm oracle-instantclient11.2-devel-11.2.0.3.0-1.i386.rpm 1.2 下载地址: http://www.oracle.com/technetwork/database/features/instant-client/index-097480.html (Oracle官网下载需要注册用户) 安装oracle客户端,运行以下命令即可: rpm -ivh oracle-instantclient11.2-basic-11.2.0.3.0.i386.rpm rpm -ivh oracle-instantclient11.2-devel-11.2.0.3.0.i386.rpm 安装oci8 php扩展 3.1 下载oci8-1.4.10.tgz 下载地址:http://pecl.php.net/get/oci8-1.4.10.tgz 3.2 把下载文件上传至linux服务器,并进行解压 命令:tar zxvf oci8-1.4.10.tgz#解压 3.3 转到解压目录 命令:cd oci8-1.4.10 3.4 使用phpize准备 PHP 外挂模块的编译环境，会根据指定的环境变量生成编译时需要的makefile，phpize是属于php-devel的内容，所以centos下只要运行yum install php-devel进行安装即可 (注意:/usr/local/php/bin/phpize 为我的php目录,不同则需改之;如果是64位的系统，client改成client64) /usr/local/php/bin/phpize CFLAGS=”-I/usr/lib/oracle/11.1/client” CXXFLAGS=”-I/usr/lib/oracle/11.1/client” 3.5 编译，安装 要有与现有php完全相同的php压缩包。我用的是php-5.5.3.tar.gz。展开后进入里面的ext/oci8目录下, 然后执行命令: /usr/local/php/bin/phpize #这是一个可执行的文本文件，要确保它在系统中 会发现当前目录下多了一些configure文件， 如果没报错，则运行命令; ./configure –with-php-config=/usr/local/php/bin/php-config –with-oci8=/usr/lib/oracle/11.1/client 注意要先确保/usr/local/php/bin/php-config存在。如果你的php安装路径不是默认的，要改。 再运行以下命令 ，然后它告诉你一个目录,你把该目录下的oci8.so拷贝到你php.ini中的extension_dir指向的目录中 make make install 1). 需要强调的是make的时候会报错，显示各种找不到库文件，需要对makefile文件进行修改加入oralce的运行库地址 打开makefile，寻找INCLUDE，形式如下： INCLUDES = -I/usr/local/php/include/php -I/usr/include/oracle/10.2.0.3/client 然后在末尾加上=”-I/usr/lib/oracle/11.1/client，然后重新make就会成功了。 2) 编译的时候会出现错误： 1234567891011121314/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:56:17: 错误：oci.h：没有那个文件或目录In file included from /data/lnmp1.4c/oci8-1.4.10/oci8.c:58:/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:113: 错误：expected specifier-qualifier-list before ‘OCIEnv’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:122: 错误：expected specifier-qualifier-list before ‘OCIEnv’In file included from /data/lnmp1.4c/oci8-1.4.10/oci8.c:58:/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:152: 错误：expected specifier-qualifier-list before ‘dvoid’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:165: 错误：expected specifier-qualifier-list before ‘ub4’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:172: 错误：expected specifier-qualifier-list before ‘OCIType’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:182: 错误：expected specifier-qualifier-list before ‘text’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:191: 错误：expected specifier-qualifier-list before ‘sword’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:207: 错误：expected specifier-qualifier-list before ‘OCIBind’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:230: 错误：expected specifier-qualifier-list before ‘OCIDefine’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:377: 错误：expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘php_oci_error’/data/lnmp1.4c/oci8-1.4.10/php_oci8_int.h:378: 错误：expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘php_oci_fetch_errmsg’ ​ error: oci8_dtrace_gen.h: No such file or directory 如果需要 DTRACE: yum install systemtap-sdt-develexport PHP_DTRACE=yes如果不需要 DTRACE: 123modify the file &apos;php_oci8_int.h&apos;, change the 48th line #include &quot;oci8_dtrace_gen.h&quot; to #undef HAVE_OCI8_DTRACE 修改PHP.ini（/usr/local/php/etc/php.ini） 在extension_dir = &quot;/usr/local/php/lib/php/extensions/no-debug-non-zts-20060613/&quot;后增加一行： extension = &quot;oci8.so&quot; 注意:要确保/usr/local/php/lib/php/extensions/no-debug-non-zts-20060613/ 该目录下有oci8.so文件 ​ 重启apache,让oci生效 在web目录下创建phpinfo.php文件在其中输入一下内容，并通过web访问]]></content>
  </entry>
  <entry>
    <title><![CDATA[通过SSH协议采集监控数据]]></title>
    <url>%2F2018%2F04%2F11%2F%E9%80%9A%E8%BF%87SSH%E5%8D%8F%E8%AE%AE%E9%87%87%E9%9B%86%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[通过SSH协议采集监控数据Zabbix中通过SSH协议也可以实现监控目标，通过SSH agent监控方式，需要对服务器进行监控但又不能安装Zabbix agent的环境中非常有用。Zabbix中使用SSh agent时要求libssh2的最低版本是 1.0.0。 SSH agent支持两种身份认证的方式：基于用户名密码的方式和基于秘钥的方式，使用用户名密码的方式不需要任何特殊的配置，添加监控项时需要在页面中输入明文的用户名和密码，因此在实际环境中建议使用基于秘钥的方式，但这个方式需要做些额外的配置。下面我们来看看基于秘钥的方式如何配置的。 首先，检查zabbix用户的设置，使用下面的命令。# grep zabbix /etc/passwd zabbix:x:996:994:Zabbix Monitoring System:/var/lib/zabbix:/sbin/nologin ​ 可以看到系统中zabbix用户的home目录是/var/lib/zabbix，确认该目录是否存在，如果不存在，使用下面的命令创建目录。 ​ # mkdir –p /var/lib/zabbix/.ssh ​ # chown –R zabbix:zabbix /var/lib/zabbix 接下来我们需要修改zabbix-server.conf文件，配置SSH Key文件的存储路径。 vi /etc/zabbix/zabbix-server.confSSHKeyLocation=/ var/lib/zabbix/.ssh修改完zabbix-server.conf配置文件后重启Zabbixserver。1systemctl restart zabbix-server 现在，我们生成zabbix用户的SSH Key，询问passphrase时直接回车就可以。 sudo -u zabbixssh-keygen -t rsa -b 2048 Generating public/private rsa key pair. Enter file in which to save the key (/var/lib/zabbix/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /var/lib/zabbix/.ssh/id_rsa. Your public key has been saved in /var/lib/zabbix/.ssh/id_rsa.pub. The key fingerprint is: 15:3e:d5:61:ed:16:b3:0a:67:9d:35:f0:35:55:0b:7e zabbix@zbxserver The key‘s randomart image is: +–[ RSA 2048]- —–+ | . .+++*| | . o..++*| | + ..EB| | . o o.+o| | S + .. | | . | | | | | | | +—————————-+ # ll total 8 -rw——- 1 zabbix zabbix 1675 May 31 13:29 id_rsa -rw-r–r– 1 zabbix zabbix 398 May 31 13:29 id_rsa.pub 接下来拷贝秘钥文件到被监控主机中，假设被监控主机的IP 地址是192.168.10.112。 # sudo -u zabbixssh-copy-id root@192.168.10.112 The authenticity of host ‘192.168.10.112 (192.168.10.112)‘ can‘t beestablished. ECDSA key fingerprint is0d:33:e5:5c:43:c3:5b:c4:da:e4:f0:6d:0c:fb:4a:6e. Are you sure you want to continue connecting (yes/no)? yes /bin/ssh-copy-id: INFO: attempting to log in with the new key(s), tofilter out any that are already installed /bin/ssh-copy-id: INFO: 1 key(s) remain to be installed – if youare prompted now it is to install the new keys root@192.168.10.112‘s password: Number of key(s) added: 1 Now try logging into the machine, with: “ssh ‘root@192.168.10.112‘“ and check to make sure that only the key(s) you wanted were added. 现在我们测试一下能否登录成功。 # sudo -u zabbix ssh root@192.168.10.112 当完成上面的配置后，就可以创建SSH agent监控方式的监控项了。 配置SSH agent监控项的步骤： 1、 创建一个新主机（Configuration –&gt; Host –&gt; Create host）。在主机配置页面的Host标签下添加Agentinterfaces接口配置，如下图3-14所示。 图 3-14 2、 在主机中创建新的监控项。 Name中输入监控项名称，例如Check uname。 Type中选择SSH agent。 Key中内容替换成ssh.run[uname]。 Host interface 中选择agent接口。 Authentication method中选择Public key。 User name中填写root ，Public key file中填写id_rsa_pub，Private keyfile中填写 id_rsa。 Key passphrase留空，如果生成密钥时你输入了passphrase，就需要在这里输入相同的passphrase。 Executed script中输入uname -a。 Type of information中选择Text类型。 其他参数可以保持不变，点击Add按钮保存。 如下图3—15所示。 图 3-15 3、 Monitoring –&gt; Latest data页面查看监控项。 使用SSH agent监控方式需要注意的是libssh2可能会把可执行脚本的输出截断到32KB，另外在脚本中最好使用命令的全路径。]]></content>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Typora小改造]]></title>
    <url>%2F2018%2F04%2F11%2FTypora%E5%B0%8F%E6%94%B9%E9%80%A0%2F</url>
    <content type="text"><![CDATA[使用Typora 链接WebSocket修改文件windows.html (line 82) 在后面添加收到的WebSocket信息接收element如下： 123456&lt;li&gt; &lt;span class="footer-word-count-info-line" style="font-weight: bold"&gt; &lt;span class="footer-word-count-no-selection" data-lg="Panel"&gt;SHELL&lt;/span&gt; &lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;p id="shell-output"&gt;&lt;/p&gt;&lt;/li&gt; 随后加入输入框和按钮1234&lt;div class="footer-item footer-item-left" id="terminal"&gt;&lt;label&gt;SHELL:&lt;/label&gt;&lt;input type="text" id='shell' name="shell" value="pwd" /&gt;&lt;button type="submit" onclick="execs()" class="footer-item-right footer-btn " id="toggle-exec-btn"&gt;Exec&lt;/button&gt;&lt;/div&gt; 增加js脚本123456789101112131415161718192021222324252627282930var ws; function make_terminal(element, size, ws_url,paramter) &#123; ws = new WebSocket(ws_url); ws.onopen = function (event) &#123; ws.send(JSON.stringify(&#123;"parameter":paramter&#125;)); ws.onmessage = function (event) &#123; json_msg = JSON.parse(event.data); console.log(json_msg); switch (json_msg[0]) &#123; case "stdout": element.innerHTML="message:" + json_msg[1]; break; case "disconnect": element.innerHTML="[Finished...]"; break; &#125; &#125;; ws.close = function (argument) &#123;console.log(argument);&#125;; &#125;; &#125;; var ws_scheme = window.location.protocol == "https:" ? "wss" : "ws"; var ws_path = ws_scheme + '://127.0.0.1:8001/exec/';function execs() &#123; var message = &#123; common: $('#shell').val(), &#125; if(document.body.classList.contains("show-word-count"))&#123;console.log(1);&#125;else document.body.classList.add("show-word-count"); make_terminal(document.getElementById('shell-output'), &#123;rows: 1, cols: 90&#125;, ws_path, message); &#125;;]]></content>
      <tags>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbiz使用之添加NGINX监控]]></title>
    <url>%2F2018%2F04%2F11%2Fzabbiz%E4%BD%BF%E7%94%A8%E4%B9%8B%E6%B7%BB%E5%8A%A0NGINX%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[zabbix使用之添加NGINX监控Agent端首先要检查Nginx是否安装了 http_stub_status_module 模块，通过下面的命令可以看到编译参数。 1nginx -V 如果没有这个模块，还需要重新编译Nginx. 配置NginxNginx 80端口的server配置增加如下的片段 location /nginx_status { stub_status on; access_log off; allow 127.0.0.1; deny all; } 检查 http://xx.x.x.x/nginx_status/ 12345&gt;&gt; curl http://127.0.0.1/nginx_statusActive connections: 4 server accepts handled requests 1162961 1162961 1210587 Reading: 0 Writing: 1 Waiting: 3 zabbix-agent 配置有3个步骤，首先是编写获取Nginx信息脚本，接着配置中增加key信息，然后重启agent 服务。 编写Nginx监控脚本，记住路径，后面配置需要用到。 ！！注意脚本权限问题，agent运行用户要能执行。 1234&gt;&gt;# mkdir -p /etc/zabbix-agent/scripts&gt;&gt;# cd /etc/zabbix-agent/scripts&gt;&gt;# vim nginx-check.sh&gt;&gt;# cat nginx-check.sh 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/bin/bash################################### Zabbix monitoring script## nginx:# - anything available via nginx stub-status module#################################### Contact:# vincent.viallet@gmail.com# Zabbix requested parameterZBX_REQ_DATA="$1"ZBX_REQ_DATA_URL="$2"# Nginx defaultsNGINX_STATUS_DEFAULT_URL="http://127.0.0.1/nginx_status"WGET_BIN="/usr/bin/wget"## Error handling:# - need to be displayable in Zabbix (avoid NOT_SUPPORTED)# - items need to be of type "float" (allow negative + float)#ERROR_NO_ACCESS_FILE="-0.9900"ERROR_NO_ACCESS="-0.9901"ERROR_WRONG_PARAM="-0.9902"ERROR_DATA="-0.9903" # either can not connect / bad host / bad port# Handle host and port if non-defaultif [ ! -z "$ZBX_REQ_DATA_URL" ]; then URL="$ZBX_REQ_DATA_URL"else URL="$NGINX_STATUS_DEFAULT_URL"fi# save the nginx stats in a variable for future parsingNGINX_STATS=$($WGET_BIN -q $URL -O - 2&gt; /dev/null)# error during retrieveif [ $? -ne 0 -o -z "$NGINX_STATS" ]; then echo $ERROR_DATA exit 1fi## Extract data from nginx stats#case $ZBX_REQ_DATA in active_connections) echo "$NGINX_STATS" | head -1 | cut -f3 -d' ';; accepted_connections) echo "$NGINX_STATS" | grep -Ev '[a-zA-Z]' | cut -f2 -d' ';; handled_connections) echo "$NGINX_STATS" | grep -Ev '[a-zA-Z]' | cut -f3 -d' ';; handled_requests) echo "$NGINX_STATS" | grep -Ev '[a-zA-Z]' | cut -f4 -d' ';; reading) echo "$NGINX_STATS" | tail -1 | cut -f2 -d' ';; writing) echo "$NGINX_STATS" | tail -1 | cut -f4 -d' ';; waiting) echo "$NGINX_STATS" | tail -1 | cut -f6 -d' ';; *) echo $ERROR_WRONG_PARAM; exit 1;;esacexit 0 agent的配置文件 /etc/zabbix/zabbix_agentd.conf 中定义了其他key的包含目录 Include=/etc/zabbix/zabbix_agentd.d/, 如果没有这个配置请自己添加下。接着在 /etc/zabbix/zabbix_agentd.d/ 目录新建一个文件 nginx-params.conf, 内容如下 1UserParameter=nginx[*],/usr/local/zabbix-agent/scripts/nginx-check.sh "$1" 重启agent 1/etc/init.d/zabbix-agent restart Server 的Web端首先命令行测试下刚才agent好使不，确认好用之后在web端导入模板，之后就可以给对应主机添加监控喽。 123zabbix_get -s 127.0.0.1 -p 10050 -k "nginx[reading]"0123 登录Zabbix3.0 的web界面，一次选择 Configuration &gt; Templates ， 在主界面的右上角有个 Import 按钮，用来导入模板。 模板文件比较长留一个下载地址 导入之后就可以给主机添加监控啦。]]></content>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbiz使用之添加Mysql监控]]></title>
    <url>%2F2018%2F04%2F11%2Fzabbiz%E4%BD%BF%E7%94%A8%E4%B9%8B%E6%B7%BB%E5%8A%A0Mysql%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[添加 Mysql 监控Agent 端配置：在/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf 文件中指定了 zabbix agent如何获取 mysql 服务的各种登录信息，并在/var/lib/zabbix/目录中新建”.my.cnf”文件，用以指定 zabbix agent 如何登陆数据库，默认使用的是 zabbix 用户，可以在 zabbix_conf文件中找到密码。 12345678910111213141516#mkdir /var/lib/zabbix#vim /var/lib/zabbix/.my.cnf[mysql]host=localhostuser=zabbixpassword=zabbixsocket=/var/lib/mysql/mysql.sock[mysqladmin]host=localhostuser=zabbixpassword=zabbixsocket=/var/lib/mysql/mysql.sock#service zabbix-agent restart#在数据库中进行授权：Mysql&gt; GRANT USAGE ON *.* TO zabbix@localhost IDENTIFIED BY ‘zabbix’;Mysql&gt;FLUSH PRIVILEGES; 在 zabbix_server 端测试是否可以得到检测数据：zabbix_get -s 10.10.1.13 -p 10050 -k mysql.ping1如显示 1，则代表可以通过zabbix_agent 获取到数据。Web 端配置：依次点击 组态–主机–（要监控 mysql 的主机）–模板–选择–Template App Mysql–添加–更新。完成后，点击监测中图形，选择主机和 Mysql bandwidth，等待检测。]]></content>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORACLE11G 链接缓慢问题排查]]></title>
    <url>%2F2018%2F04%2F08%2FORACLE11G-%E9%93%BE%E6%8E%A5%E7%BC%93%E6%85%A2%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[问题描述： 服务器centos7,客服端任意 本地使用sqlplus / 连接很快，sqlplus xxx/xxx@127.0.0.1/sid 很慢 windows客服端在创建链接后也很慢 问题排查 tnsping 没有延迟 11G用户验证问题（只要有登陆错误，就会有延迟累计）－－－－－－不是 监听文件配置问题 －－－－－－不是 日志文件过大 －－－－－－－不是 机器名在监听文件和网络上的名字不一致－－－－－－－是 /etc/hosts /etc/hostname $ORACLE_HOME/network/admin/tnsname.ora /etc/sysconf/network ​]]></content>
      <tags>
        <tag>linux,ORACLE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gateone]]></title>
    <url>%2F2018%2F03%2F13%2Fgateone%2F</url>
    <content type="text"><![CDATA[1. Gate One简介GateOne是一款基于HTML5的开源终端模拟器/SSH客户端。它可以用于运行任何终端应用。用户可以将GateOne嵌入其他应用程序从而提供各类终端访问界面，它也支持各类基于Web的管理界面。 Gate One在后台进程是使用Python实现的，其前端则是JaveScript+WebSockets。关于Gate One的介绍、源码和文档请参考下面的链接。 Gate One主页：http://liftoffsoftware.com/Products/GateOneGate One源码：https://github.com/liftoff/GateOneGate One文档：http://liftoff.github.io/GateOne/ 2. Gate One安装Gate One要求系统必须满足下面两个前提条件， （1）python: 2.6+ or 3.2+ （2）Tornado Framework 2.2+ 2.1系统环境准备在命令行终端中输入命令 $ python -V查看你本机是否安装了python，如果先安装python（注：树莓派上面自己带有python2和python3，python2对应python命令，python3对应python3命令）。 然后安装pip， $ wget --no-check-certificate https://bootstrap.pypa.io/get-pip.py $ sudo python get-pip.py 安装tornado， $ sudo pip install tornado 安装完成之后，我们来验证一下我们的环境， $ python -V $ python -c &quot;import tornado; print(tornado.version)&quot; 2.2 Gate One获取和安装如果本地没有安装git，则先安装git， $ sudo apt-get install git 获取Gate One源码并进行安装，（注：这个地方git clone会下载到当前目录下！所以下载前记得cd到你想下载的位置目录去） $ git clone https://github.com/liftoff/GateOne.git $ cd GateOne $ sudo python ./setup.py install 3. Gate One验证Gate One的配置文件是/etc/gateone/conf.d/10server.conf， sudo vi /etc/gateone/conf.d/10server.conf 我们修改配置文件如下图： 这里我们修改了：“address” = “192.168.1.2” 这个是树莓派的ip地址“https_redirect” = “true”“port” = 8000 这个是监听端口 其他默认就可以了输入命令： $ sudo gateone 启动后，通过打印的信息，我们看到Gate One服务监听了8000端口号，然后在浏览器中输入https://192.168.1.106:8000/即可打开gateone的网页网络会进行拦截，点击 高级 ——添加例外——确认即可然后点击中间的Terminal图标登陆某台机器，到此链接成功，可以web浏览器远程终端操作树莓派了（这个地方我修改了端口号：8008，因为前面多次操作，出现下面遇到的问题！）多次链接可能会出现这种情况：红色错误显示不能监听，端口被占用了，可以修改签名配置文件端口号。重新测试。 4. 配置auth pam安装libpam_pwdfile包 sudo apt install libpam_pwdfile vi /etc/gateone/conf.d/20authentication.conf auth = &quot;pam&quot; pam_realm = &quot;AccessGateway1&quot; pam_service = &quot;gateone&quot; 在Safari下无法使用，报错如下：The WebSocket connection was closed. Will attempt to reconnect every 5 seconds…NOTE: Some web proxies do not work properly with WebSockets. PC和Android中的Chrome正常。 vi /etc/pam.d/gateone #%PAM-1.0 # Login using a htpasswd file #@include common-sessionauth required pam_pwdfile.so pwdfile=/etc/gateone/passwd required pam_permit.so auth = &quot;pam&quot; pam_realm = &quot;AccessGateway1&quot; pam_service = &quot;gateone&quot; 密码生成用在线工具就行，记得选择Crypt方式：http://tool.oschina.net/htpasswd将生成的信息加入密码文件就行。 sudo htpasswd -c -d /etc/gateone/users.passwd user1]]></content>
      <categories>
        <category>堡垒机</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>gateone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[my git]]></title>
    <url>%2F2018%2F03%2F13%2Fmy-git%2F</url>
    <content type="text"><![CDATA[my git]]></content>
  </entry>
  <entry>
    <title><![CDATA[oracle 11g 在centos7上静默安装与安装时的错误处理]]></title>
    <url>%2F2017%2F10%2F07%2Farticle-title%2F</url>
    <content type="text"><![CDATA[分类：oracle版权声明：本文为博主原创文章，未经博主允许不得转载。本次（2017-03-11）修改：1）修改程序安装目录名 /home —&gt; /data2）删减了一些不必要的包（ksh）3）增加了rlwrap 一个可以在sqlplus中可以使用键盘方向键来回找历史命令。4）增加了一些关键的截图，为帮助有需要的朋友理好知道安装进度5）蓝色字体、双#号是新增说明 1、准备系统、软件#oracle 11g：linux.x64_11gR2_database_2of2.ziplinux.x64_11gR2_database_1of2.zip #SYSTEMCentOS7 X86_64 2、安装依赖库#下载安装pdksh rpm -ivh pdksh-5.2.14-37.el5_8.1.x86_64.rpm ##： 安装这个pdksh rpm包时可能会出现与ksh冲突问题，如果不使用ksh可以把ksh卸载了，我安装了非常多次发现并不影响使用—-（2017-03-11） #安装其它依赖yum -y install binutils compat-libcap1 compat-libstdc++ gcc gcc-c++ glibc glibc-devel libgcc libstdc++ libstdc++-devel libaio sysstat libaio-devel elfutils-libelf-devel unixODBC unixODBC-devel ##： 删除了ksh安装包 3、用户目录创建groupadd oinstallgroupadd dbauseradd -m -g oinstall -G dba oracleecho “oracle:password” | chpasswdmkdir -p /home/oracle/ora11gchown -R oracle:oinstall /home/oracle/ora11gchmod -R 775 /home/oracle/ora11g 4、系统配置#内核参数调整cat &gt;&gt; /etc/sysctl.conf &lt;&lt;EOFfs.aio-max-nr = 3145728fs.file-max = 6815744kernel.shmall = 1073741824kernel.shmmax = 4398046511104kernel.shmmni = 4096kernel.sem = 250 32000 100 142net.ipv4.ip_local_port_range = 9000 65500net.core.rmem_default = 262144net.core.rmem_max = 4194304net.core.wmem_default = 262144net.core.wmem_max = 1048576EOF #配置全局变量cat &gt;&gt; /etc/profile &lt;&lt;EOFif [ $USER = “oracle” ]; then if [ $SHELL = “/bin/ksh” ];then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fifiEOF ##：这个环境变量发现并没有什么用（重复配置），因为后面配置文件句柄数时已经永久配置了参数。 #配置oracle用户变量cat &gt;&gt; /data/oracle/.bash_profile &lt;&lt;EOFexport TMP=/tmpexport TMPDIR=$TMPexport ORACLE_HOSTNAME=$(hostname)export ORACLE_BASE=/data/oracle/ora11gexport ORACLE_HOME=/data/oracle/ora11g/product/11.2.0/db_1export ORACLE_SID=orcl11gexport ORACLE_TERM=xtermexport PATH=$ORACLE_HOME/bin:$PATH #以下配置在参考别人写时是要配置的，但是我加上后，系统命令无法执行，就直接注释了 #export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib64:/usr/lib:/usr/lib64:/usr/local/lib64 #export CLASSPATH=$ORACLE_HOME/JRE:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib #export LD_ASSUME_KERNEL=2.6.18 ##：直接删除了export NLS_LANG=”american_america.UTF8”export NLS_LANG=”AMERICAN_AMERICA.US7ASCII”EOF #给oracle用户配置句柄数和文件打开数cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOForacle soft nproc 2048oracle hard nproc 16384oracle soft nofile 1024oracle hard nofile 65536EOF #配置oracle用户变量cat &gt;&gt; /home/oracle/.bashrc &lt;&lt;EOFalias sysdba=’sqlplus “/ nolog”‘EOF #配置oracle系统配置文件cat &gt;&gt; /etc/oraInst.loc &lt;&lt;EOFinventory_loc=/data/oracle/ora11g/oraInventoryinst_group=oinstallEOF #授权chmod 664 /etc/oraInst.loc #加载内核参数sysctl -p #给安装文件授权，我这里放在oracle home目录下chown -R oracle:oinstall /home/oracle/database #添加swap文件 #虚拟机没有或者不够swap空间dd if=/dev/zero of=/data/swap4g bs=1M count=4096mkswap /data/swap4gchmod 600 /data/swap4gswapon /data/swap4g ##：修改了文件/home/swap — &gt; /data/swap4g 5、安装、安装排错#解压安装文件 #配置静默安装应答文件su oracle ; cd ~cp /home/oracle/database/response/* . #配置初始化安装文件sed -i ‘s/oracle.install.option=./oracle.install.option=INSTALL_DB_SWONLY/g’ db_install.rspsed -i “s/ORACLE_HOSTNAME=./ORACLE_HOSTNAME=$(hostname)/g” db_install.rspsed -i ‘s/UNIX_GROUP_NAME=./UNIX_GROUP_NAME=oinstall/g’ db_install.rspsed -i ‘s/INVENTORY_LOCATION=./INVENTORY_LOCATION=\/data\/oracle\/ora11g\/oraInventory/g’ db_install.rspsed -i ‘s/SELECTED_LANGUAGES=./SELECTED_LANGUAGES=en,zh_CN/g’ db_install.rspsed -i ‘s/ORACLE_HOME=./ORACLE_HOME=\/data\/oracle\/ora11g\/product\/11.2.0\/db_1/g’ db_install.rspsed -i ‘s/ORACLE_BASE=./ORACLE_BASE=\/data\/oracle\/ora11g/g’ db_install.rspsed -i ‘s/oracle.install.db.InstallEdition=./oracle.install.db.InstallEdition=EE/g’ db_install.rspsed -i ‘s/oracle.install.db.isCustomInstall=./oracle.install.db.isCustomInstall=true/g’ db_install.rspsed -i ‘s/oracle.install.db.DBA_GROUP=./oracle.install.db.DBA_GROUP=dba/g’ db_install.rspsed -i ‘s/oracle.install.db.OPER_GROUP=./oracle.install.db.OPER_GROUP=oinstall/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.type=./oracle.install.db.config.starterdb.type=GENERAL_PURPOSE/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.globalDBName=./oracle.install.db.config.starterdb.globalDBName=ora11g/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.SID=./oracle.install.db.config.starterdb.SID=orcl/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.characterSet=./oracle.install.db.config.starterdb.characterSet=AL32UTF8/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.memoryOption=./oracle.install.db.config.starterdb.memoryOption=true/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.password.ALL=./oracle.install.db.config.starterdb.password.ALL=oracle/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.control=./oracle.install.db.config.starterdb.control=DB_CONTROL/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.dbcontrol.enableEmailNotification=./oracle.install.db.config.starterdb.dbcontrol.enableEmailNotification=true/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.dbcontrol.emailAddress=./oracle.install.db.config.starterdb.dbcontrol.emailAddress=test@test.com/g’ db_install.rspsed -i ‘s/oracle.install.db.config.starterdb.dbcontrol.SMTPServer=./oracle.install.db.config.starterdb.dbcontrol.SMTPServer=smtp.test.com/g’ db_install.rspsed -i ‘s/DECLINE_SECURITY_UPDATES=./DECLINE_SECURITY_UPDATES=true/g’ db_install.rspchmod 640 db_install.rsp ##：修改目录配置/home —&gt; /data ##：修正在sed 参数 #配置监听应答文件sed -i ‘s/INSTALL_TYPE=.*/INSTALL_TYPE=””custom””/g’ netca.rsp #配置数据库应答文件sed -i ‘s#GDBNAME =.#GDBNAME = “orcl11g”#g’ dbca.rspsed -i ‘s#SID =.#SID = “orcl11g”#g’ dbca.rspsed -i ‘s/#SYSPASSWORD =./SYSPASSWORD = “oracle”/g’ dbca.rspsed -i ‘s/#SYSTEMPASSWORD =./SYSPASSWORD = “oracle”/g’ dbca.rsp #安装/home/oracle/database/runInstaller -silent -responseFile /home/oracle/db_install.rsp #先使用上面命令检查系统环境合不合格，如果出现依赖库版本不对（一般是系统的版本高了，oracle要求的版本低一些）和一些内核参数检测不出来（并不是没有配置），这些可以忽略。如果其它的报错根据报错去给系统作相应的调整吧。 #排错只能看日志，没有其它更好的办法。 #比如以下错误都可以忽略801:INFO: Error Message:PRVF-7543 : 操作系统内核参数 “semmni” 在节点 “centos7-6” 上没有适当的值 [应为 = “128”; 找到 = “0”]。930:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “libaio-0.3.105 (i386)”951:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “glibc-2.3.4-2.41 (i686)”972:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “compat-libstdc++-33-3.2.3 (i386)”984:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “compat-libstdc++-33-3.2.3 (x86_64)”1050:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “libaio-devel-0.3.105 (i386)”1071:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “libgcc-3.4.6 (i386)”1092:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “libstdc++-3.4.6 (i386)”1131:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “unixODBC-2.2.11 (i386)”1152:INFO: Error Message:PRVF-7532 : 节点 “centos7-6” 上缺少程序包 “unixODBC-devel-2.2.11 (i386)” ##：新增错误信息 #以下命令是忽略那些可忽略参数的命令/home/oracle/database/runInstaller -silent -ignorePrereq -responseFile /home/oracle/db_install.rsp #检测安完成后，会提示用root用户执行以下面的命令去完成最后的安装sh /home/oracle/ora11g/product/11.2.0/db_1/root.sh ##：到目前为止，oracle已经全部安装完成 6、创建实例、监听文件#创建实例dbca -silent -responseFile /home/oracle/dbca.rsp #创建监听netca /silent /responseFile /home/oracle/netca.rsp #查看oracle的状态 7、安装rlwrapyum install readline* ncurses-develtar xf rlwrap-0.30.tar.gz.zipcd rlwrap-0.30./configuremakemake install #直接配置在.bash_profile里alias sqlplus=’rlwrap sqlplus’alias rman=’rlwrap rman’ source .bash_profile #里边涉及的一些敏感数据就不打码了，因为都在VM里跑的。。。 #主要参考文章出处：http://blog.csdn.net/dc666/article/details/50014693，非常感谢！]]></content>
  </entry>
</search>
